<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/../../../../Client/archiver.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/archiver.py" />
              <option name="originalContent" value="import os&#10;import shutil&#10;&#10;&#10;class Archiver:&#10;    def __init__(self, archive_dir='archive'):&#10;// ...existing code...&#10;&#10;" />
              <option name="updatedContent" value="import os&#13;&#10;import shutil&#13;&#10;&#13;&#10;&#13;&#10;class Archiver:&#13;&#10;    def __init__(self, archive_dir='archive'):&#13;&#10;        self.archive_dir = archive_dir&#13;&#10;        if not os.path.exists(self.archive_dir):&#13;&#10;            os.makedirs(self.archive_dir)&#13;&#10;&#13;&#10;    def archive_directory(self, source_dir):&#13;&#10;        &quot;&quot;&quot;Archives a directory by moving it into the archive directory.&quot;&quot;&quot;&#13;&#10;        try:&#13;&#10;            # Generate a unique name for the archive directory&#13;&#10;            timestamp = datetime.datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;)&#13;&#10;            archive_name = f&quot;{os.path.basename(source_dir)}_{timestamp}&quot;&#13;&#10;            destination_dir = os.path.join(self.archive_dir, archive_name)&#13;&#10;&#13;&#10;            # Move the directory&#13;&#10;            shutil.move(source_dir, destination_dir)&#13;&#10;            print(f&quot;Directory '{source_dir}' archived to '{destination_dir}'&quot;)&#13;&#10;            return destination_dir&#13;&#10;        except Exception as e:&#13;&#10;            print(f&quot;Error archiving directory '{source_dir}': {e}&quot;)&#13;&#10;            return None&#13;&#10;&#13;&#10;    def restore_directory(self, archive_path, destination_dir):&#13;&#10;        &quot;&quot;&quot;Restores a directory from the archive.&quot;&quot;&quot;&#13;&#10;        try:&#13;&#10;            # Move the directory back&#13;&#10;            shutil.move(archive_path, destination_dir)&#13;&#10;            print(f&quot;Directory '{archive_path}' restored to '{destination_dir}'&quot;)&#13;&#10;            return destination_dir&#13;&#10;        except Exception as e:&#13;&#10;            print(f&quot;Error restoring directory '{archive_path}': {e}&quot;)&#13;&#10;            return None" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/contributor_wall_app.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/contributor_wall_app.py" />
              <option name="originalContent" value="// ...existing code...&#10;class ContributorWallApp:&#10;    def __init__(self, root):&#10;// ...existing code...&#10;        self.title_label = tk.Label(root, text=&quot;Nexapod Contributor Wall&quot;,&#10;                                    font=(&quot;Helvetica&quot;, 24, &quot;bold&quot;),&#10;                                    bg=&quot;#2E2E2E&quot;, fg=&quot;#FFFFFF&quot;)&#10;        self.title_label.pack(pady=20)&#10;&#10;        self.canvas = tk.Canvas(root, bg=&quot;#2E2E2E&quot;, highlightthickness=0)&#10;        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)&#10;&#10;        self.scrollbar = tk.Scrollbar(root, orient=tk.VERTICAL,&#10;                                      command=self.canvas.yview)&#10;        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)&#10;        self.canvas.configure(yscrollcommand=self.scrollbar.set)&#10;&#10;        self.contributors_frame = tk.Frame(self.canvas, bg=&quot;#2E2E2E&quot;)&#10;        self.canvas.create_window((0, 0), window=self.contributors_frame,&#10;                                  anchor=tk.NW)&#10;&#10;        self.contributors_data = [&#10;            {&quot;name&quot;: &quot;Kunya&quot;, &quot;image_path&quot;: &quot;assets/kunya.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/kunya66&quot;},&#10;            {&quot;name&quot;: &quot;ChatGPT&quot;, &quot;image_path&quot;: &quot;assets/chatgpt.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/chatgpt&quot;},&#10;            {&quot;name&quot;: &quot;Gemini&quot;, &quot;image_path&quot;: &quot;assets/gemini.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/gemini&quot;},&#10;            {&quot;name&quot;: &quot;Claude&quot;, &quot;image_path&quot;: &quot;assets/claude.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/claude&quot;},&#10;            {&quot;name&quot;: &quot;Other Contributor 1&quot;,&#10;             &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/contributor1&quot;},&#10;            {&quot;name&quot;: &quot;Other Contributor 2&quot;,&#10;             &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/contributor2&quot;},&#10;            {&quot;name&quot;: &quot;Other Contributor 3&quot;,&#10;             &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/contributor3&quot;},&#10;            {&quot;name&quot;: &quot;Other Contributor 4&quot;,&#10;             &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/contributor4&quot;},&#10;            {&quot;name&quot;: &quot;Other Contributor 5&quot;,&#10;             &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/contributor5&quot;},&#10;            {&quot;name&quot;: &quot;Other Contributor 6&quot;,&#10;             &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;             &quot;github_url&quot;: &quot;https://github.com/contributor6&quot;},&#10;        ]&#10;&#10;        self.create_contributor_widgets()&#10;        self.contributors_frame.bind(&quot;&lt;Configure&gt;&quot;, self.on_frame_configure)&#10;        self.canvas.bind_all(&quot;&lt;MouseWheel&gt;&quot;, self.on_mouse_wheel)&#10;&#10;    def on_frame_configure(self, event):&#10;        self.canvas.configure(scrollregion=self.canvas.bbox(&quot;all&quot;))&#10;&#10;    def on_mouse_wheel(self, event):&#10;        self.canvas.yview_scroll(int(-1 * (event.delta / 120)), &quot;units&quot;)&#10;&#10;    def create_contributor_widgets(self):&#10;        for i, contributor in enumerate(self.contributors_data):&#10;            row, col = divmod(i, 4)&#10;            contributor_frame = tk.Frame(self.contributors_frame,&#10;                                         bg=&quot;#3C3C3C&quot;, relief=tk.RAISED,&#10;                                         borderwidth=2)&#10;            contributor_frame.grid(row=row, column=col, padx=20, pady=20,&#10;                                   sticky=&quot;nsew&quot;)&#10;&#10;            try:&#10;                img = Image.open(contributor[&quot;image_path&quot;])&#10;                img = img.resize((100, 100), Image.Resampling.LANCZOS)&#10;                photo = ImageTk.PhotoImage(img)&#10;                image_label = tk.Label(contributor_frame, image=photo,&#10;                                       bg=&quot;#3C3C3C&quot;)&#10;                image_label.image = photo&#10;                image_label.pack(pady=10)&#10;            except FileNotFoundError:&#10;                # Handle case where image is not found&#10;                placeholder_label = tk.Label(contributor_frame,&#10;                                             text=&quot;Image not found&quot;,&#10;                                             bg=&quot;#3C3C3C&quot;, fg=&quot;#FFFFFF&quot;)&#10;                placeholder_label.pack(pady=10)&#10;&#10;            name_label = tk.Label(contributor_frame, text=contributor[&quot;name&quot;],&#10;                                  font=(&quot;Helvetica&quot;, 12, &quot;bold&quot;),&#10;                                  bg=&quot;#3C3C3C&quot;, fg=&quot;#FFFFFF&quot;)&#10;            name_label.pack()&#10;&#10;            github_link = tk.Label(contributor_frame, text=&quot;GitHub Profile&quot;,&#10;                                   font=(&quot;Helvetica&quot;, 10, &quot;underline&quot;),&#10;                                   fg=&quot;#1E90FF&quot;, bg=&quot;#3C3C3C&quot;, cursor=&quot;hand2&quot;)&#10;            github_link.pack(pady=5)&#10;            github_link.bind(&quot;&lt;Button-1&gt;&quot;, lambda e,&#10;                             url=contributor[&quot;github_url&quot;]: self.open_link(url))&#10;&#10;    def open_link(self, url):&#10;        webbrowser.open_new(url)&#10;&#10;&#10;def main():&#10;    root = tk.Tk()&#10;    app = ContributorWallApp(root)&#10;    root.mainloop()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;&#10;" />
              <option name="updatedContent" value="import tkinter as tk&#13;&#10;import webbrowser&#13;&#10;from PIL import Image, ImageTk&#13;&#10;&#13;&#10;&#13;&#10;class ContributorWallApp:&#13;&#10;    def __init__(self, root):&#13;&#10;        self.root = root&#13;&#10;        self.root.title(&quot;NexaPod Contributor Wall&quot;)&#13;&#10;        self.root.geometry(&quot;1200x800&quot;)&#13;&#10;        self.root.configure(bg=&quot;#2E2E2E&quot;)&#13;&#10;&#13;&#10;        self.title_label = tk.Label(&#13;&#10;            root,&#13;&#10;            text=&quot;Nexapod Contributor Wall&quot;,&#13;&#10;            font=(&quot;Helvetica&quot;, 24, &quot;bold&quot;),&#13;&#10;            bg=&quot;#2E2E2E&quot;,&#13;&#10;            fg=&quot;#FFFFFF&quot;,&#13;&#10;        )&#13;&#10;        self.title_label.pack(pady=20)&#13;&#10;&#13;&#10;        self.canvas = tk.Canvas(root, bg=&quot;#2E2E2E&quot;, highlightthickness=0)&#13;&#10;        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)&#13;&#10;&#13;&#10;        self.scrollbar = tk.Scrollbar(&#13;&#10;            root, orient=tk.VERTICAL, command=self.canvas.yview&#13;&#10;        )&#13;&#10;        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)&#13;&#10;        self.canvas.configure(yscrollcommand=self.scrollbar.set)&#13;&#10;&#13;&#10;        self.contributors_frame = tk.Frame(self.canvas, bg=&quot;#2E2E2E&quot;)&#13;&#10;        self.canvas.create_window(&#13;&#10;            (0, 0), window=self.contributors_frame, anchor=tk.NW&#13;&#10;        )&#13;&#10;&#13;&#10;        self.contributors_data = [&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Kunya&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/kunya.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/kunya66&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;ChatGPT&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/chatgpt.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/chatgpt&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Gemini&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/gemini.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/gemini&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Claude&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/claude.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/claude&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 1&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor1&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 2&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor2&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 3&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor3&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 4&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor4&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 5&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor5&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 6&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor6&quot;,&#13;&#10;            },&#13;&#10;        ]&#13;&#10;&#13;&#10;        self.create_contributor_widgets()&#13;&#10;        self.contributors_frame.bind(&quot;&lt;Configure&gt;&quot;, self.on_frame_configure)&#13;&#10;        self.canvas.bind_all(&quot;&lt;MouseWheel&gt;&quot;, self.on_mouse_wheel)&#13;&#10;&#13;&#10;    def on_frame_configure(self, event):&#13;&#10;        self.canvas.configure(scrollregion=self.canvas.bbox(&quot;all&quot;))&#13;&#10;&#13;&#10;    def on_mouse_wheel(self, event):&#13;&#10;        self.canvas.yview_scroll(int(-1 * (event.delta / 120)), &quot;units&quot;)&#13;&#10;&#13;&#10;    def create_contributor_widgets(self):&#13;&#10;        for i, contributor in enumerate(self.contributors_data):&#13;&#10;            row, col = divmod(i, 4)&#13;&#10;            contributor_frame = tk.Frame(&#13;&#10;                self.contributors_frame,&#13;&#10;                bg=&quot;#3C3C3C&quot;,&#13;&#10;                relief=tk.RAISED,&#13;&#10;                borderwidth=2,&#13;&#10;            )&#13;&#10;            contributor_frame.grid(&#13;&#10;                row=row, column=col, padx=20, pady=20, sticky=&quot;nsew&quot;&#13;&#10;            )&#13;&#10;&#13;&#10;            try:&#13;&#10;                img = Image.open(contributor[&quot;image_path&quot;])&#13;&#10;                img = img.resize((100, 100), Image.Resampling.LANCZOS)&#13;&#10;                photo = ImageTk.PhotoImage(img)&#13;&#10;                image_label = tk.Label(&#13;&#10;                    contributor_frame, image=photo, bg=&quot;#3C3C3C&quot;&#13;&#10;                )&#13;&#10;                image_label.image = photo&#13;&#10;                image_label.pack(pady=10)&#13;&#10;            except FileNotFoundError:&#13;&#10;                # Handle case where image is not found&#13;&#10;                placeholder_label = tk.Label(&#13;&#10;                    contributor_frame,&#13;&#10;                    text=&quot;Image not found&quot;,&#13;&#10;                    bg=&quot;#3C3C3C&quot;,&#13;&#10;                    fg=&quot;#FFFFFF&quot;,&#13;&#10;                )&#13;&#10;                placeholder_label.pack(pady=10)&#13;&#10;&#13;&#10;            name_label = tk.Label(&#13;&#10;                contributor_frame,&#13;&#10;                text=contributor[&quot;name&quot;],&#13;&#10;                font=(&quot;Helvetica&quot;, 12, &quot;bold&quot;),&#13;&#10;                bg=&quot;#3C3C3C&quot;,&#13;&#10;                fg=&quot;#FFFFFF&quot;,&#13;&#10;            )&#13;&#10;            name_label.pack()&#13;&#10;&#13;&#10;            github_link = tk.Label(&#13;&#10;                contributor_frame,&#13;&#10;                text=&quot;GitHub Profile&quot;,&#13;&#10;                font=(&quot;Helvetica&quot;, 10, &quot;underline&quot;),&#13;&#10;                fg=&quot;#1E90FF&quot;,&#13;&#10;                bg=&quot;#3C3C3C&quot;,&#13;&#10;                cursor=&quot;hand2&quot;,&#13;&#10;            )&#13;&#10;            github_link.pack(pady=5)&#13;&#10;            github_link.bind(&#13;&#10;                &quot;&lt;Button-1&gt;&quot;,&#13;&#10;                lambda e, url=contributor[&quot;github_url&quot;]: self.open_link(url),&#13;&#10;            )&#13;&#10;&#13;&#10;    def open_link(self, url):&#13;&#10;        webbrowser.open_new(url)&#13;&#10;&#13;&#10;&#13;&#10;def main():&#13;&#10;    root = tk.Tk()&#13;&#10;    app = ContributorWallApp(root)&#13;&#10;    root.mainloop()&#13;&#10;&#13;&#10;&#13;&#10;if __name__ == &quot;__main__&quot;:&#13;&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/dashboard.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/dashboard.py" />
              <option name="updatedContent" value="// ...existing code...&#10;from .contributor_wall_app import ContributorWallApp&#10;from .nexapod_client import NexaPodClient&#10;&#10;# Constants&#10;// ...existing code...&#10;# ...existing code...&#10;class ToolTip:&#10;    def __init__(self, widget, text):&#10;// ...existing code...&#10;        self.widget.bind(&quot;&lt;Leave&gt;&quot;, self.hidetip)&#10;&#10;    def showtip(self, event=None):&#10;// ...existing code...&#10;        x = y = 0&#10;        x, y, cx, cy = self.widget.bbox(&quot;insert&quot;)&#10;        x += self.widget.winfo_rootx() + 25&#10;        y += self.widget.winfo_rooty() + 20&#10;        self.tw.wm_geometry(f&quot;+{x}+{y}&quot;)&#10;        self.tw.wm_deiconify()&#10;&#10;    def hidetip(self, event=None):&#10;        if self.tw:&#10;            self.tw.wm_withdraw()&#10;&#10;&#10;class Dashboard:&#10;    def __init__(self, root):&#10;        self.root = root&#10;// ...existing code...&#10;        self.root.title(&quot;NexaPod Dashboard&quot;)&#10;        self.root.geometry(&quot;1200x800&quot;)&#10;        self.root.configure(bg=BG_COLOR)&#10;&#10;        self.client = NexaPodClient()&#10;        self.style = ttk.Style()&#10;        self.style.theme_use('clam')&#10;        self.configure_styles()&#10;&#10;        self.create_widgets()&#10;&#10;    def configure_styles(self):&#10;        self.style.configure(&quot;TFrame&quot;, background=BG_COLOR)&#10;        self.style.configure(&quot;TLabel&quot;, background=BG_COLOR,&#10;                             foreground=TEXT_COLOR,&#10;                             font=(FONT_FAMILY, 12))&#10;        self.style.configure(&quot;Header.TLabel&quot;, font=(FONT_FAMILY, 24, &quot;bold&quot;))&#10;        self.style.configure(&quot;TButton&quot;, background=BUTTON_COLOR,&#10;                             foreground=TEXT_COLOR,&#10;                             font=(FONT_FAMILY, 12, &quot;bold&quot;),&#10;                             borderwidth=1)&#10;        self.style.map(&quot;TButton&quot;,&#10;                       background=[('active', BUTTON_HOVER_COLOR)])&#10;        self.style.configure(&quot;TEntry&quot;,&#10;                             fieldbackground=ENTRY_BG_COLOR,&#10;                             foreground=TEXT_COLOR,&#10;                             insertcolor=TEXT_COLOR)&#10;        self.style.configure(&quot;Treeview&quot;,&#10;                             background=ENTRY_BG_COLOR,&#10;                             foreground=TEXT_COLOR,&#10;                             fieldbackground=ENTRY_BG_COLOR,&#10;                             font=(FONT_FAMILY, 10))&#10;        self.style.map(&quot;Treeview&quot;,&#10;                       background=[('selected', BUTTON_COLOR)])&#10;        self.style.configure(&quot;Treeview.Heading&quot;,&#10;                             background=BUTTON_COLOR,&#10;                             foreground=TEXT_COLOR,&#10;                             font=(FONT_FAMILY, 12, &quot;bold&quot;))&#10;&#10;    def create_widgets(self):&#10;        # Header&#10;        header_frame = ttk.Frame(self.root)&#10;        header_frame.pack(pady=20, padx=20, fill='x')&#10;        header_label = ttk.Label(header_frame, text=&quot;NexaPod Dashboard&quot;,&#10;                                 style=&quot;Header.TLabel&quot;)&#10;        header_label.pack()&#10;&#10;        # Main content frame&#10;        main_frame = ttk.Frame(self.root)&#10;        main_frame.pack(expand=True, fill='both', padx=20, pady=10)&#10;&#10;        # Left panel for controls&#10;        left_panel = ttk.Frame(main_frame, width=400)&#10;        left_panel.pack(side='left', fill='y', padx=(0, 10))&#10;        left_panel.pack_propagate(False)&#10;&#10;        # Right panel for logs and info&#10;        right_panel = ttk.Frame(main_frame)&#10;        right_panel.pack(side='right', expand=True, fill='both')&#10;&#10;        # Control sections in left panel&#10;        self.create_profile_section(left_panel)&#10;        self.create_task_section(left_panel)&#10;        self.create_network_section(left_panel)&#10;        self.create_actions_section(left_panel)&#10;&#10;        # Info sections in right panel&#10;        self.create_log_section(right_panel)&#10;        self.create_stats_section(right_panel)&#10;&#10;    def create_profile_section(self, parent):&#10;        profile_frame = ttk.LabelFrame(parent, text=&quot;User Profile&quot;,&#10;                                       padding=(10, 5))&#10;        profile_frame.pack(pady=10, fill='x')&#10;&#10;        ttk.Label(profile_frame, text=&quot;Username:&quot;).grid(row=0, column=0,&#10;                                                        sticky='w', pady=2)&#10;        self.username_entry = ttk.Entry(profile_frame, width=30)&#10;        self.username_entry.grid(row=0, column=1, sticky='ew', pady=2)&#10;&#10;        ttk.Label(profile_frame, text=&quot;Private Key:&quot;).grid(row=1, column=0,&#10;                                                           sticky='w', pady=2)&#10;        self.private_key_entry = ttk.Entry(profile_frame, width=30, show=&quot;*&quot;)&#10;        self.private_key_entry.grid(row=1, column=1, sticky='ew', pady=2)&#10;&#10;        profile_buttons_frame = ttk.Frame(profile_frame)&#10;        profile_buttons_frame.grid(row=2, column=0, columnspan=2, pady=5)&#10;&#10;        self.load_profile_button = ttk.Button(profile_buttons_frame,&#10;                                              text=&quot;Load Profile&quot;,&#10;                                              command=self.load_profile)&#10;        self.load_profile_button.pack(side='left', padx=5)&#10;        self.create_profile_button = ttk.Button(profile_buttons_frame,&#10;                                                text=&quot;Create Profile&quot;,&#10;                                                command=self.create_profile)&#10;        self.create_profile_button.pack(side='left', padx=5)&#10;&#10;    def create_task_section(self, parent):&#10;        task_frame = ttk.LabelFrame(parent, text=&quot;Task Management&quot;,&#10;                                    padding=(10, 5))&#10;        task_frame.pack(pady=10, fill='x')&#10;&#10;        ttk.Label(task_frame, text=&quot;Task Type:&quot;).grid(row=0, column=0,&#10;                                                      sticky='w', pady=2)&#10;        self.task_type_combo = ttk.Combobox(&#10;            task_frame,&#10;            values=[&quot;protein_folding&quot;, &quot;molecular_docking&quot;, &quot;image_analysis&quot;])&#10;        self.task_type_combo.grid(row=0, column=1, sticky='ew', pady=2)&#10;        self.task_type_combo.set(&quot;protein_folding&quot;)&#10;&#10;        ttk.Label(task_frame, text=&quot;Task Data (JSON):&quot;).grid(row=1, column=0,&#10;                                                             sticky='w',&#10;                                                             pady=2)&#10;        self.task_data_text = tk.Text(task_frame, height=5, width=40,&#10;                                      bg=ENTRY_BG_COLOR, fg=TEXT_COLOR,&#10;                                      insertbackground=TEXT_COLOR)&#10;        self.task_data_text.grid(row=2, column=0, columnspan=2,&#10;                                 sticky='ew', pady=2)&#10;&#10;        self.submit_task_button = ttk.Button(task_frame, text=&quot;Submit Task&quot;,&#10;                                             command=self.submit_task)&#10;        self.submit_task_button.grid(row=3, column=0, columnspan=2, pady=10)&#10;&#10;    def create_network_section(self, parent):&#10;        network_frame = ttk.LabelFrame(parent, text=&quot;Network Status&quot;,&#10;                                       padding=(10, 5))&#10;        network_frame.pack(pady=10, fill='x')&#10;&#10;        self.network_status_label = ttk.Label(network_frame,&#10;                                              text=&quot;Status: Disconnected&quot;,&#10;                                              foreground=&quot;red&quot;)&#10;        self.network_status_label.pack(pady=5)&#10;&#10;        self.connect_button = ttk.Button(network_frame, text=&quot;Connect&quot;,&#10;                                         command=self.connect_to_network)&#10;        self.connect_button.pack(pady=5)&#10;&#10;    def create_actions_section(self, parent):&#10;        actions_frame = ttk.LabelFrame(parent, text=&quot;Actions&quot;,&#10;                                       padding=(10, 5))&#10;        actions_frame.pack(pady=10, fill='x')&#10;&#10;        self.view_tasks_button = ttk.Button(actions_frame,&#10;                                            text=&quot;View My Tasks&quot;,&#10;                                            command=self.view_my_tasks)&#10;        self.view_tasks_button.pack(fill='x', pady=5)&#10;&#10;        self.contributor_wall_button = ttk.Button(&#10;            actions_frame,&#10;            text=&quot;Show Contributor Wall&quot;,&#10;            command=self.show_contributor_wall)&#10;        self.contributor_wall_button.pack(fill='x', pady=5)&#10;&#10;    def create_log_section(self, parent):&#10;        log_frame = ttk.LabelFrame(parent, text=&quot;Logs&quot;, padding=(10, 5))&#10;        log_frame.pack(expand=True, fill='both', pady=(0, 10))&#10;&#10;        self.log_text = tk.Text(log_frame, height=15,&#10;                                bg=ENTRY_BG_COLOR, fg=TEXT_COLOR,&#10;                                state='disabled', wrap='word')&#10;        self.log_text.pack(expand=True, fill='both', padx=5, pady=5)&#10;&#10;        log_scrollbar = ttk.Scrollbar(self.log_text,&#10;                                      command=self.log_text.yview)&#10;        log_scrollbar.pack(side='right', fill='y')&#10;        self.log_text['yscrollcommand'] = log_scrollbar.set&#10;&#10;    def create_stats_section(self, parent):&#10;        stats_frame = ttk.LabelFrame(parent, text=&quot;Statistics&quot;,&#10;                                     padding=(10, 5))&#10;        stats_frame.pack(fill='x')&#10;&#10;        self.stats_tree = ttk.Treeview(stats_frame, columns=(&quot;Value&quot;),&#10;                                       show=&quot;headings&quot;, height=5)&#10;        self.stats_tree.heading(&quot;Value&quot;, text=&quot;Value&quot;)&#10;        self.stats_tree.column(&quot;Value&quot;, width=150)&#10;        self.stats_tree.pack(expand=True, fill='both', padx=5, pady=5)&#10;&#10;        self.stats_tree.insert(&quot;&quot;, &quot;end&quot;, text=&quot;Reputation&quot;,&#10;                               values=(&quot;N/A&quot;,))&#10;        self.stats_tree.insert(&quot;&quot;, &quot;end&quot;, text=&quot;Tasks Completed&quot;,&#10;                               values=(&quot;N/A&quot;,))&#10;        self.stats_tree.insert(&quot;&quot;, &quot;end&quot;, text=&quot;NexaTokens Earned&quot;,&#10;                               values=(&quot;N/A&quot;,))&#10;        self.stats_tree.insert(&quot;&quot;, &quot;end&quot;, text=&quot;Tier&quot;,&#10;                               values=(&quot;N/A&quot;,))&#10;        self.stats_tree.insert(&quot;&quot;, &quot;end&quot;, text=&quot;Network Peers&quot;,&#10;                               values=(&quot;N/A&quot;,))&#10;&#10;    def log(self, message):&#10;        self.log_text.config(state='normal')&#10;        self.log_text.insert('end', f&quot;{message}\n&quot;)&#10;        self.log_text.config(state='disabled')&#10;        self.log_text.see('end')&#10;&#10;    def load_profile(self):&#10;        username = self.username_entry.get()&#10;        private_key = self.private_key_entry.get()&#10;        if not username or not private_key:&#10;            messagebox.showerror(&quot;Error&quot;,&#10;                                 &quot;Username and Private Key are required.&quot;)&#10;            return&#10;        try:&#10;            self.client.load_profile(username, private_key)&#10;            self.log(f&quot;Profile for '{username}' loaded successfully.&quot;)&#10;            self.update_stats()&#10;        except Exception as e:&#10;            messagebox.showerror(&quot;Profile Load Error&quot;, str(e))&#10;            self.log(f&quot;Failed to load profile for '{username}': {e}&quot;)&#10;&#10;    def create_profile(self):&#10;        username = self.username_entry.get()&#10;        if not username:&#10;            messagebox.showerror(&quot;Error&quot;, &quot;Username is required.&quot;)&#10;            return&#10;        try:&#10;            private_key = self.client.create_profile(username)&#10;            self.private_key_entry.delete(0, 'end')&#10;            self.private_key_entry.insert(0, private_key)&#10;            self.log(f&quot;Profile for '{username}' created.&quot;)&#10;            self.log(&quot;Your private key has been generated. &quot;&#10;                     &quot;Store it securely!&quot;)&#10;            self.update_stats()&#10;        except Exception as e:&#10;            messagebox.showerror(&quot;Profile Creation Error&quot;, str(e))&#10;            self.log(f&quot;Failed to create profile for '{username}': {e}&quot;)&#10;&#10;    def submit_task(self):&#10;        if not self.client.profile:&#10;            messagebox.showerror(&quot;Error&quot;, &quot;Please load or create a profile &quot;&#10;                                          &quot;before submitting a task.&quot;)&#10;            return&#10;&#10;        task_type = self.task_type_combo.get()&#10;        task_data_str = self.task_data_text.get(&quot;1.0&quot;, 'end-1c')&#10;&#10;        if not task_type or not task_data_str:&#10;            messagebox.showerror(&quot;Error&quot;, &quot;Task Type and Task Data are &quot;&#10;                                          &quot;required.&quot;)&#10;            return&#10;&#10;        try:&#10;            task_data = json.loads(task_data_str)&#10;            task_id = self.client.submit_task(task_type, task_data)&#10;            self.log(f&quot;Task '{task_id}' submitted successfully.&quot;)&#10;            messagebox.showinfo(&quot;Success&quot;,&#10;                                f&quot;Task submitted with ID: {task_id}&quot;)&#10;        except json.JSONDecodeError:&#10;            messagebox.showerror(&quot;Error&quot;, &quot;Invalid JSON in Task Data.&quot;)&#10;            self.log(&quot;Error: Invalid JSON format in task data.&quot;)&#10;        except Exception as e:&#10;            messagebox.showerror(&quot;Task Submission Error&quot;, str(e))&#10;            self.log(f&quot;Failed to submit task: {e}&quot;)&#10;&#10;    def connect_to_network(self):&#10;        self.log(&quot;Attempting to connect to the NexaPod network...&quot;)&#10;        # This is a placeholder for actual network connection logic&#10;        # In a real app, this would involve P2P discovery, etc.&#10;        self.network_status_label.config(text=&quot;Status: Connected&quot;,&#10;                                         foreground=&quot;green&quot;)&#10;        self.log(&quot;Successfully connected to the network.&quot;)&#10;        # Simulate updating peer count&#10;        self.stats_tree.item(self.stats_tree.get_children()[4],&#10;                             values=(f&quot;{random.randint(5, 50)}&quot;,))&#10;&#10;    def update_stats(self):&#10;        if self.client.profile:&#10;            reputation = self.client.get_reputation()&#10;            tasks_completed = len(self.client.get_completed_tasks())&#10;            # Placeholder for token calculation&#10;            tokens = tasks_completed * 10&#10;            tier = self.client.get_tier()&#10;&#10;            self.stats_tree.item(self.stats_tree.get_children()[0],&#10;                                 values=(f&quot;{reputation}&quot;,))&#10;            self.stats_tree.item(self.stats_tree.get_children()[1],&#10;                                 values=(f&quot;{tasks_completed}&quot;,))&#10;            self.stats_tree.item(self.stats_tree.get_children()[2],&#10;                                 values=(f&quot;{tokens} NT&quot;,))&#10;            self.stats_tree.item(self.stats_tree.get_children()[3],&#10;                                 values=(f&quot;{tier}&quot;,))&#10;            self.log(&quot;User stats updated.&quot;)&#10;        else:&#10;            self.log(&quot;Cannot update stats, no profile loaded.&quot;)&#10;&#10;    def view_my_tasks(self):&#10;        if not self.client.profile:&#10;            messagebox.showerror(&quot;Error&quot;, &quot;Please load a profile first.&quot;)&#10;            return&#10;&#10;        tasks = self.client.get_all_tasks()&#10;        if not tasks:&#10;            messagebox.showinfo(&quot;My Tasks&quot;, &quot;You have no tasks.&quot;)&#10;            return&#10;&#10;        task_window = tk.Toplevel(self.root)&#10;        task_window.title(&quot;My Tasks&quot;)&#10;        task_window.geometry(&quot;600x400&quot;)&#10;        task_window.configure(bg=BG_COLOR)&#10;&#10;        task_tree = ttk.Treeview(task_window,&#10;                                 columns=(&quot;ID&quot;, &quot;Type&quot;, &quot;Status&quot;),&#10;                                 show=&quot;headings&quot;)&#10;        task_tree.heading(&quot;ID&quot;, text=&quot;Task ID&quot;)&#10;        task_tree.heading(&quot;Type&quot;, text=&quot;Type&quot;)&#10;        task_tree.heading(&quot;Status&quot;, text=&quot;Status&quot;)&#10;        task_tree.pack(expand=True, fill='both', padx=10, pady=10)&#10;&#10;        for task_id, task_info in tasks.items():&#10;            task_tree.insert(&quot;&quot;, &quot;end&quot;, values=(&#10;                task_id, task_info['type'], task_info['status']))&#10;&#10;    def show_contributor_wall(self):&#10;        contributor_window = tk.Toplevel(self.root)&#10;        contributor_window.title(&quot;Contributor Wall&quot;)&#10;        contributor_window.geometry(&quot;800x600&quot;)&#10;        ContributorWallApp(contributor_window)&#10;&#10;&#10;def main():&#10;    root = tk.Tk()&#10;    app = Dashboard(root)&#10;    root.mainloop()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/descriptor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/descriptor.py" />
              <option name="updatedContent" value="import json&#10;&#10;&#10;class Descriptor:&#10;    def __init__(self, file_path):&#10;        self.file_path = file_path&#10;// ...existing code...&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/executor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/executor.py" />
              <option name="updatedContent" value="import subprocess&#10;import json&#10;&#10;&#10;class Executor:&#10;    def execute_task(self, task_data):&#10;        &quot;&quot;&quot;&#10;        Executes a task based on its type.&#10;        This is a simplified executor. A real implementation would be more&#10;        robust, sandboxed, and support different environments.&#10;        &quot;&quot;&quot;&#10;        task_type = task_data.get('type')&#10;        if task_type == 'execute_script':&#10;            script_path = task_data.get('script_path')&#10;            try:&#10;                result = subprocess.run(['python', script_path],&#10;                                        capture_output=True, text=True,&#10;                                        check=True)&#10;                return {&quot;stdout&quot;: result.stdout, &quot;stderr&quot;: result.stderr}&#10;            except subprocess.CalledProcessError as e:&#10;                return {&quot;error&quot;: str(e), &quot;stdout&quot;: e.stdout,&#10;                        &quot;stderr&quot;: e.stderr}&#10;            except FileNotFoundError:&#10;                return {&quot;error&quot;: f&quot;Script not found at {script_path}&quot;}&#10;        elif task_type == 'data_processing':&#10;            # Example of another task type&#10;            data = task_data.get('data')&#10;            # Process the data in some way&#10;            processed_data = {&quot;processed_length&quot;: len(data)}&#10;            return {&quot;result&quot;: processed_data}&#10;        else:&#10;            return {&quot;error&quot;: f&quot;Unsupported task type: {task_type}&quot;}&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/input_fetch.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/input_fetch.py" />
              <option name="updatedContent" value="import requests&#10;&#10;&#10;class InputFetcher:&#10;    def fetch(self, url):&#10;        try:&#10;// ...existing code...&#10;            response.raise_for_status()&#10;            return response.text&#10;        except requests.exceptions.RequestException as e:&#10;            print(f&quot;Error fetching input from {url}: {e}&quot;)&#10;            return None&#10;&#10;&#10;class FileInputFetcher:&#10;    def fetch(self, file_path):&#10;        try:&#10;// ...existing code...&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/ledger.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/ledger.py" />
              <option name="updatedContent" value="// ...existing code...&#10;class Ledger:&#10;    def __init__(self, db_path='ledger.db'):&#10;// ...existing code...&#10;        self._create_tables()&#10;&#10;    def _create_tables(self):&#10;        &quot;&quot;&quot;Create the necessary tables if they don't exist.&quot;&quot;&quot;&#10;// ...existing code...&#10;            c.execute('''&#10;                CREATE TABLE IF NOT EXISTS transactions (&#10;                    id TEXT PRIMARY KEY,&#10;                    timestamp REAL,&#10;                    type TEXT,&#10;                    data TEXT,&#10;                    signature TEXT&#10;                )&#10;            ''')&#10;            self.conn.commit()&#10;&#10;    def add_transaction(self, transaction):&#10;// ...existing code...&#10;        with self.lock:&#10;            c = self.conn.cursor()&#10;            c.execute(&quot;INSERT INTO transactions VALUES (?, ?, ?, ?, ?)&quot;,&#10;                      (tx_id, tx_timestamp, tx_type, tx_data, tx_signature))&#10;            self.conn.commit()&#10;        return tx_id&#10;&#10;&#10;class Transaction:&#10;    def __init__(self, tx_type, data, key_manager):&#10;        self.id = None&#10;// ...existing code...&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/logger.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/logger.py" />
              <option name="updatedContent" value="import logging&#10;from cryptography.hazmat.primitives import hashes&#10;from cryptography.hazmat.primitives.asymmetric import padding&#10;&#10;# Configure logging&#10;logging.basicConfig(level=logging.INFO,&#10;// ...existing code...&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/../../../../Client/nexapod_client.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/../../../../Client/nexapod_client.py" />
              <option name="updatedContent" value="// ...existing code...&#10;class NexaPodClient:&#10;    def __init__(self, server_url=&quot;http://127.0.0.1:5000&quot;):&#10;        self.server_url = server_url&#10;// ...existing code...&#10;        self.reputation_manager = ReputationManager()&#10;        self.tier_manager = TierManager()&#10;&#10;    def create_profile(self, username):&#10;        if self.profiles.get_profile(username):&#10;            raise ValueError(f&quot;Profile for '{username}' already exists.&quot;)&#10;        private_key, public_key = self.key_manager.generate_keys()&#10;        self.profiles.create_profile(username, public_key)&#10;        # In a real app, the private key should be handled more securely&#10;        # (e.g., encrypted storage)&#10;        print(f&quot;Generated private key for {username}: {private_key}&quot;)&#10;        self.load_profile(username, private_key)&#10;        return private_key&#10;&#10;    def load_profile(self, username, private_key):&#10;        profile_data = self.profiles.get_profile(username)&#10;        if not profile_data:&#10;            raise ValueError(f&quot;No profile found for '{username}'.&quot;)&#10;        # In a real app, you'd verify the private key matches the public key&#10;        self.profile = {&quot;username&quot;: username, &quot;private_key&quot;: private_key,&#10;                        &quot;public_key&quot;: profile_data['public_key']}&#10;        print(f&quot;Profile for {username} loaded.&quot;)&#10;&#10;    def submit_task(self, task_type, task_data):&#10;        if not self.profile:&#10;            raise ConnectionError(&quot;No profile loaded. Please create or load &quot;&#10;                                  &quot;a profile first.&quot;)&#10;&#10;        task = {&#10;            &quot;id&quot;: str(uuid.uuid4()),&#10;            &quot;type&quot;: task_type,&#10;            &quot;data&quot;: task_data,&#10;            &quot;submitter&quot;: self.profile['username'],&#10;            &quot;timestamp&quot;: time.time(),&#10;            &quot;status&quot;: &quot;pending&quot;&#10;        }&#10;        # Sign the task to prove identity&#10;        signature = self.key_manager.sign(self.profile['private_key'],&#10;                                          json.dumps(task, sort_keys=True))&#10;        &#10;        payload = {&quot;task&quot;: task, &quot;signature&quot;: signature}&#10;&#10;        try:&#10;            response = requests.post(f&quot;{self.server_url}/submit_task&quot;,&#10;                                     json=payload)&#10;            response.raise_for_status()&#10;            self.ledger.add_transaction(&#10;                Transaction(&quot;submit_task&quot;, payload, self.key_manager))&#10;            return task['id']&#10;        except requests.exceptions.RequestException as e:&#10;            print(f&quot;Error submitting task to server: {e}&quot;)&#10;            raise&#10;&#10;    def get_reputation(self):&#10;        if not self.profile:&#10;            return 0&#10;        return self.reputation_manager.get_reputation(&#10;            self.profile['username'])&#10;&#10;    def get_completed_tasks(self):&#10;        # This would fetch from a local DB or the network&#10;        return []&#10;&#10;    def get_all_tasks(self):&#10;        # Placeholder to get tasks from the ledger/local state&#10;        return {}&#10;&#10;    def get_tier(self):&#10;        if not self.profile:&#10;            return &quot;N/A&quot;&#10;        reputation = self.get_reputation()&#10;        return self.tier_manager.get_tier(reputation)&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Client/contributor_wall_app.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Client/contributor_wall_app.py" />
              <option name="originalContent" value="import tkinter as tk&#10;import webbrowser&#10;from PIL import Image, ImageTk&#10;&#10;&#10;class ContributorWallApp:&#10;    def __init__(self, root):&#10;        self.root = root&#10;        self.root.title(&quot;NexaPod Contributor Wall&quot;)&#10;        self.root.geometry(&quot;1200x800&quot;)&#10;        self.root.configure(bg=&quot;#2E2E2E&quot;)&#10;&#10;        self.title_label = tk.Label(&#10;            root,&#10;            text=&quot;Nexapod Contributor Wall&quot;,&#10;            font=(&quot;Helvetica&quot;, 24, &quot;bold&quot;),&#10;            bg=&quot;#2E2E2E&quot;,&#10;            fg=&quot;#FFFFFF&quot;,&#10;        )&#10;        self.title_label.pack(pady=20)&#10;&#10;        self.canvas = tk.Canvas(root, bg=&quot;#2E2E2E&quot;, highlightthickness=0)&#10;        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)&#10;&#10;        self.scrollbar = tk.Scrollbar(&#10;            root, orient=tk.VERTICAL, command=self.canvas.yview&#10;        )&#10;        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)&#10;        self.canvas.configure(yscrollcommand=self.scrollbar.set)&#10;&#10;        self.contributors_frame = tk.Frame(self.canvas, bg=&quot;#2E2E2E&quot;)&#10;        self.canvas.create_window(&#10;            (0, 0), window=self.contributors_frame, anchor=tk.NW&#10;        )&#10;&#10;        self.contributors_data = [&#10;            {&#10;                &quot;name&quot;: &quot;Kunya&quot;,&#10;                &quot;image_path&quot;: &quot;assets/kunya.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/kunya66&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;ChatGPT&quot;,&#10;                &quot;image_path&quot;: &quot;assets/chatgpt.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/chatgpt&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Gemini&quot;,&#10;                &quot;image_path&quot;: &quot;assets/gemini.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/gemini&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Claude&quot;,&#10;                &quot;image_path&quot;: &quot;assets/claude.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/claude&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Other Contributor 1&quot;,&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor1&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Other Contributor 2&quot;,&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor2&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Other Contributor 3&quot;,&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor3&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Other Contributor 4&quot;,&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor4&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Other Contributor 5&quot;,&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor5&quot;,&#10;            },&#10;            {&#10;                &quot;name&quot;: &quot;Other Contributor 6&quot;,&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor6&quot;,&#10;            },&#10;        ]&#10;&#10;        self.create_contributor_widgets()&#10;        self.contributors_frame.bind(&quot;&lt;Configure&gt;&quot;, self.on_frame_configure)&#10;        self.canvas.bind_all(&quot;&lt;MouseWheel&gt;&quot;, self.on_mouse_wheel)&#10;&#10;    def on_frame_configure(self, event):&#10;        self.canvas.configure(scrollregion=self.canvas.bbox(&quot;all&quot;))&#10;&#10;    def on_mouse_wheel(self, event):&#10;        self.canvas.yview_scroll(int(-1 * (event.delta / 120)), &quot;units&quot;)&#10;&#10;    def create_contributor_widgets(self):&#10;        for i, contributor in enumerate(self.contributors_data):&#10;            row, col = divmod(i, 4)&#10;            contributor_frame = tk.Frame(&#10;                self.contributors_frame,&#10;                bg=&quot;#3C3C3C&quot;,&#10;                relief=tk.RAISED,&#10;                borderwidth=2,&#10;            )&#10;            contributor_frame.grid(&#10;                row=row, column=col, padx=20, pady=20, sticky=&quot;nsew&quot;&#10;            )&#10;&#10;            try:&#10;                img = Image.open(contributor[&quot;image_path&quot;])&#10;                img = img.resize((100, 100), Image.Resampling.LANCZOS)&#10;                photo = ImageTk.PhotoImage(img)&#10;                image_label = tk.Label(&#10;                    contributor_frame, image=photo, bg=&quot;#3C3C3C&quot;&#10;                )&#10;                image_label.image = photo&#10;                image_label.pack(pady=10)&#10;            except FileNotFoundError:&#10;                # Handle case where image is not found&#10;                placeholder_label = tk.Label(&#10;                    contributor_frame,&#10;                    text=&quot;Image not found&quot;,&#10;                    bg=&quot;#3C3C3C&quot;,&#10;                    fg=&quot;#FFFFFF&quot;,&#10;                )&#10;                placeholder_label.pack(pady=10)&#10;&#10;            name_label = tk.Label(&#10;                contributor_frame,&#10;                text=contributor[&quot;name&quot;],&#10;                font=(&quot;Helvetica&quot;, 12, &quot;bold&quot;),&#10;                bg=&quot;#3C3C3C&quot;,&#10;                fg=&quot;#FFFFFF&quot;,&#10;            )&#10;            name_label.pack()&#10;&#10;            github_link = tk.Label(&#10;                contributor_frame,&#10;                text=&quot;GitHub Profile&quot;,&#10;                font=(&quot;Helvetica&quot;, 10, &quot;underline&quot;),&#10;                fg=&quot;#1E90FF&quot;,&#10;                bg=&quot;#3C3C3C&quot;,&#10;                cursor=&quot;hand2&quot;,&#10;            )&#10;            github_link.pack(pady=5)&#10;            github_link.bind(&#10;                &quot;&lt;Button-1&gt;&quot;,&#10;                lambda e, url=contributor[&quot;github_url&quot;]: self.open_link(url),&#10;            )&#10;&#10;    def open_link(self, url):&#10;        webbrowser.open_new(url)&#10;&#10;&#10;def main():&#10;    root = tk.Tk()&#10;    app = ContributorWallApp(root)&#10;    root.mainloop()&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="import tkinter as tk&#13;&#10;import webbrowser&#13;&#10;from PIL import Image, ImageTk&#13;&#10;&#13;&#10;&#13;&#10;class ContributorWallApp:&#13;&#10;    def __init__(self, root):&#13;&#10;        self.root = root&#13;&#10;        self.root.title(&quot;NexaPod Contributor Wall&quot;)&#13;&#10;        self.root.geometry(&quot;1200x800&quot;)&#13;&#10;        self.root.configure(bg=&quot;#2E2E2E&quot;)&#13;&#10;&#13;&#10;        self.title_label = tk.Label(&#13;&#10;            root,&#13;&#10;            text=&quot;Nexapod Contributor Wall&quot;,&#13;&#10;            font=(&quot;Helvetica&quot;, 24, &quot;bold&quot;),&#13;&#10;            bg=&quot;#2E2E2E&quot;,&#13;&#10;            fg=&quot;#FFFFFF&quot;,&#13;&#10;        )&#13;&#10;        self.title_label.pack(pady=20)&#13;&#10;&#13;&#10;        self.canvas = tk.Canvas(root, bg=&quot;#2E2E2E&quot;, highlightthickness=0)&#13;&#10;        self.canvas.pack(side=tk.LEFT, fill=tk.BOTH, expand=True)&#13;&#10;&#13;&#10;        self.scrollbar = tk.Scrollbar(&#13;&#10;            root, orient=tk.VERTICAL, command=self.canvas.yview&#13;&#10;        )&#13;&#10;        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)&#13;&#10;        self.canvas.configure(yscrollcommand=self.scrollbar.set)&#13;&#10;&#13;&#10;        self.contributors_frame = tk.Frame(self.canvas, bg=&quot;#2E2E2E&quot;)&#13;&#10;        self.canvas.create_window(&#13;&#10;            (0, 0), window=self.contributors_frame, anchor=tk.NW&#13;&#10;        )&#13;&#10;&#13;&#10;        self.contributors_data = [&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Kunya&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/kunya.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/kunya66&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;ChatGPT&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/chatgpt.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/chatgpt&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Gemini&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/gemini.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/gemini&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Claude&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/claude.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/claude&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 1&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor1&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 2&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor2&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 3&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor3&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 4&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor4&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 5&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor5&quot;,&#13;&#10;            },&#13;&#10;            {&#13;&#10;                &quot;name&quot;: &quot;Other Contributor 6&quot;,&#13;&#10;                &quot;image_path&quot;: &quot;assets/default.png&quot;,&#13;&#10;                &quot;github_url&quot;: &quot;https://github.com/contributor6&quot;,&#13;&#10;            },&#13;&#10;        ]&#13;&#10;&#13;&#10;        self.create_contributor_widgets()&#13;&#10;        self.contributors_frame.bind(&quot;&lt;Configure&gt;&quot;, self.on_frame_configure)&#13;&#10;        self.canvas.bind_all(&quot;&lt;MouseWheel&gt;&quot;, self.on_mouse_wheel)&#13;&#10;&#13;&#10;    def on_frame_configure(self, event):&#13;&#10;        self.canvas.configure(scrollregion=self.canvas.bbox(&quot;all&quot;))&#13;&#10;&#13;&#10;    def on_mouse_wheel(self, event):&#13;&#10;        self.canvas.yview_scroll(int(-1 * (event.delta / 120)), &quot;units&quot;)&#13;&#10;&#13;&#10;    def create_contributor_widgets(self):&#13;&#10;        for i, contributor in enumerate(self.contributors_data):&#13;&#10;            row, col = divmod(i, 4)&#13;&#10;            contributor_frame = tk.Frame(&#13;&#10;                self.contributors_frame,&#13;&#10;                bg=&quot;#3C3C3C&quot;,&#13;&#10;                relief=tk.RAISED,&#13;&#10;                borderwidth=2,&#13;&#10;            )&#13;&#10;            contributor_frame.grid(&#13;&#10;                row=row, column=col, padx=20, pady=20, sticky=&quot;nsew&quot;&#13;&#10;            )&#13;&#10;&#13;&#10;            try:&#13;&#10;                img = Image.open(contributor[&quot;image_path&quot;])&#13;&#10;                img = img.resize((100, 100), Image.Resampling.LANCZOS)&#13;&#10;                photo = ImageTk.PhotoImage(img)&#13;&#10;                image_label = tk.Label(&#13;&#10;                    contributor_frame, image=photo, bg=&quot;#3C3C3C&quot;&#13;&#10;                )&#13;&#10;                image_label.image = photo&#13;&#10;                image_label.pack(pady=10)&#13;&#10;            except FileNotFoundError:&#13;&#10;                # Handle case where image is not found&#13;&#10;                placeholder_label = tk.Label(&#13;&#10;                    contributor_frame,&#13;&#10;                    text=&quot;Image not found&quot;,&#13;&#10;                    bg=&quot;#3C3C3C&quot;,&#13;&#10;                    fg=&quot;#FFFFFF&quot;,&#13;&#10;                )&#13;&#10;                placeholder_label.pack(pady=10)&#13;&#10;&#13;&#10;            name_label = tk.Label(&#13;&#10;                contributor_frame,&#13;&#10;                text=contributor[&quot;name&quot;],&#13;&#10;                font=(&quot;Helvetica&quot;, 12, &quot;bold&quot;),&#13;&#10;                bg=&quot;#3C3C3C&quot;,&#13;&#10;                fg=&quot;#FFFFFF&quot;,&#13;&#10;            )&#13;&#10;            name_label.pack()&#13;&#10;&#13;&#10;            github_link = tk.Label(&#13;&#10;                contributor_frame,&#13;&#10;                text=&quot;GitHub Profile&quot;,&#13;&#10;                font=(&quot;Helvetica&quot;, 10, &quot;underline&quot;),&#13;&#10;                fg=&quot;#1E90FF&quot;,&#13;&#10;                bg=&quot;#3C3C3C&quot;,&#13;&#10;                cursor=&quot;hand2&quot;,&#13;&#10;            )&#13;&#10;            github_link.pack(pady=5)&#13;&#10;            github_link.bind(&#13;&#10;                &quot;&lt;Button-1&gt;&quot;,&#13;&#10;                lambda e, url=contributor[&quot;github_url&quot;]: self.open_link(url),&#13;&#10;            )&#13;&#10;&#13;&#10;    def open_link(self, url):&#13;&#10;        webbrowser.open_new(url)&#13;&#10;&#13;&#10;&#13;&#10;def main():&#13;&#10;    root = tk.Tk()&#13;&#10;    ContributorWallApp(root)&#13;&#10;    root.mainloop()&#13;&#10;&#13;&#10;&#13;&#10;if __name__ == &quot;__main__&quot;:&#13;&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Client/dashboard.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Client/dashboard.py" />
              <option name="originalContent" value="import json&#10;from datetime import datetime&#10;from typing import List, Dict, Tuple&#10;&#10;import networkx as nx&#10;import numpy as np&#10;import plotly.graph_objects as go&#10;import streamlit as st&#10;&#10;st.set_page_config(&#10;    page_title=&quot;NEXAPod Dashboard&quot;,&#10;    page_icon=&quot;&quot;,&#10;    layout=&quot;wide&quot;,&#10;    initial_sidebar_state=&quot;expanded&quot;&#10;)&#10;&#10;st.markdown(&quot;&quot;&quot;&#10;&lt;style&gt;&#10;    .main-header {&#10;        font-size: 2.5rem;&#10;        font-weight: bold;&#10;        color: #2c3e50;&#10;        text-align: center;&#10;        margin-bottom: 1rem;&#10;    }&#10;    .subtitle {&#10;        text-align: center;&#10;        color: #7f8c8d;&#10;        font-size: 1.1rem;&#10;        margin-bottom: 2rem;&#10;    }&#10;    .metric-container {&#10;        background: #f8f9fa;&#10;        border: 1px solid #e9ecef;&#10;        border-radius: 8px;&#10;        padding: 1rem;&#10;        margin: 0.5rem 0;&#10;    }&#10;    .status-active { color: #27ae60; font-weight: bold; }&#10;    .status-busy { color: #f39c12; font-weight: bold; }&#10;    .status-offline { color: #e74c3c; font-weight: bold; }&#10;    .status-maintenance { color: #8e44ad; font-weight: bold; }&#10;    .sidebar-section {&#10;        background-color: #f8f9fa;&#10;        padding: 1rem;&#10;        border-radius: 6px;&#10;        margin: 1rem 0;&#10;        border-left: 3px solid #3498db;&#10;    }&#10;    .data-table {&#10;        font-size: 0.9rem;&#10;    }&#10;&lt;/style&gt;&#10;&quot;&quot;&quot;, unsafe_allow_html=True)&#10;&#10;&#10;class SpinningGlobeNetwork:&#10;    &quot;&quot;&quot;&#10;    3D Spinning Globe Network Visualization&#10;&#10;    Creates an interactive 3D visualization of a complete graph&#10;    network with nodes distributed on a sphere using a Fibonacci&#10;    spiral. Nodes use larger markers and show single-line JSON hover&#10;    information. Live animation rotates the globe and pulses nodes.&#10;    &quot;&quot;&quot;&#10;    def __init__(self, nodes_data: List[Dict]):&#10;        self.nodes_data = nodes_data&#10;        self.num_nodes = len(nodes_data)&#10;&#10;    def fibonacci_sphere_distribution(self) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:&#10;        &quot;&quot;&quot;Generate optimal node positions using Fibonacci spiral.&quot;&quot;&quot;&#10;        n = self.num_nodes&#10;        indices = np.arange(n) + 0.5&#10;        phi = np.arccos(1 - 2 * (indices / n))&#10;        theta = np.pi * (1 + np.sqrt(5)) * indices&#10;        x = np.sin(phi) * np.cos(theta)&#10;        y = np.sin(phi) * np.sin(theta)&#10;        z = np.cos(phi)&#10;        return x, y, z&#10;&#10;    @staticmethod&#10;    def create_sphere_surface(resolution: int = 50) -&gt; go.Surface:&#10;        &quot;&quot;&quot;Create the background sphere surface.&quot;&quot;&quot;&#10;        u = np.linspace(0, np.pi, resolution)&#10;        v = np.linspace(0, 2 * np.pi, resolution)&#10;        U, V = np.meshgrid(u, v)&#10;        X_sphere = np.sin(U) * np.cos(V)&#10;        Y_sphere = np.sin(U) * np.sin(V)&#10;        Z_sphere = np.cos(U)&#10;        return go.Surface(&#10;            x=X_sphere, y=Y_sphere, z=Z_sphere,&#10;            colorscale='Viridis',&#10;            opacity=0.5,&#10;            showscale=False,&#10;            hoverinfo='skip'&#10;        )&#10;&#10;    def create_network_edges(self, node_positions: Tuple[np.ndarray, ...]) -&gt; List[go.Scatter3d]:&#10;        &quot;&quot;&quot;Create edge traces for complete graph connectivity.&quot;&quot;&quot;&#10;        x_coords, y_coords, z_coords = node_positions&#10;        G = nx.complete_graph(self.num_nodes)&#10;        edge_traces = []&#10;        for edge in G.edges():&#10;            i, j = edge&#10;            edge_trace = go.Scatter3d(&#10;                x=[x_coords[i], x_coords[j]],&#10;                y=[y_coords[i], y_coords[j]],&#10;                z=[z_coords[i], z_coords[j]],&#10;                mode='lines',&#10;                line=dict(color='rgba(100, 149, 237, 0.6)', width=2),&#10;                hoverinfo='skip',&#10;                showlegend=False&#10;            )&#10;            edge_traces.append(edge_trace)&#10;        return edge_traces&#10;&#10;    def prepare_hover_information(self) -&gt; List[str]:&#10;        &quot;&quot;&quot;&#10;        Prepare JSON-formatted hover text for each node in a single-line format.&#10;        &quot;&quot;&quot;&#10;        hover_texts = []&#10;        for node in self.nodes_data:&#10;            hover_data = {&#10;                'id': node['id'],&#10;                'tier': node['tier'],&#10;                'status': node['status'],&#10;                'region': node['region'],&#10;                'cpu_usage': f&quot;{node['metrics']['cpu_usage']}%&quot;,&#10;                'memory_usage': f&quot;{node['metrics']['memory_usage']}%&quot;,&#10;                'jobs_completed': node['metrics']['jobs_completed'],&#10;                'reputation_score': node['metrics']['reputation_score'],&#10;                'credits_earned': f&quot;${node['metrics']['credits_earned']:.2f}&quot;,&#10;                'uptime_hours': node['profile']['uptime_hours']&#10;            }&#10;            hover_text = json.dumps(hover_data)&#10;            hover_texts.append(hover_text)&#10;        return hover_texts&#10;&#10;    def create_node_trace(self, node_positions: Tuple[np.ndarray, ...]) -&gt; go.Scatter3d:&#10;        &quot;&quot;&quot;Create the main node scatter trace with larger markers.&quot;&quot;&quot;&#10;        x_coords, y_coords, z_coords = node_positions&#10;        hover_texts = self.prepare_hover_information()&#10;        return go.Scatter3d(&#10;            x=x_coords, y=y_coords, z=z_coords,&#10;            mode='markers+text',&#10;            marker=dict(&#10;                symbol='circle',&#10;                size=[12] * self.num_nodes,&#10;                color='red',&#10;                line=dict(width=2, color='white'),&#10;                opacity=0.9&#10;            ),&#10;            text=[f&quot;Node {i}&quot; for i in range(self.num_nodes)],&#10;            textposition='middle center',&#10;            textfont=dict(size=10, color='white'),&#10;            hovertext=hover_texts,&#10;            hoverinfo='text',&#10;            showlegend=False&#10;        )&#10;&#10;    def generate_animation_frames(self, num_frames: int = 60) -&gt; List[Dict]:&#10;        &quot;&quot;&quot;&#10;        Generate animation frames for camera rotation and node pulsing.&#10;        &quot;&quot;&quot;&#10;        frames = []&#10;        phases = [2 * np.pi * j / self.num_nodes for j in range(self.num_nodes)]&#10;        for i in range(num_frames):&#10;            angle = 2 * np.pi * i / num_frames&#10;            cam_eye = dict(x=2 * np.cos(angle), y=2 * np.sin(angle), z=0.5)&#10;            node_sizes = [&#10;                12 + 3 * ((np.sin(2 * np.pi * i / num_frames + phases[j]) + 1) / 2)&#10;                for j in range(self.num_nodes)&#10;            ]&#10;            frame = dict(&#10;                data=[dict(marker=dict(size=node_sizes))],&#10;                traces=[1],&#10;                layout=dict(scene=dict(camera=dict(eye=cam_eye)))&#10;            )&#10;            frames.append(frame)&#10;        return frames&#10;&#10;    def create_visualization(self) -&gt; go.Figure:&#10;        &quot;&quot;&quot;Create the complete 3D spinning globe network visualization.&quot;&quot;&quot;&#10;        node_positions = self.fibonacci_sphere_distribution()&#10;        sphere_trace = self.create_sphere_surface()&#10;        node_trace = self.create_node_trace(node_positions)&#10;        edge_traces = self.create_network_edges(node_positions)&#10;        data = [sphere_trace, node_trace] + edge_traces&#10;&#10;        layout = dict(&#10;            scene=dict(&#10;                xaxis=dict(visible=False),&#10;                yaxis=dict(visible=False),&#10;                zaxis=dict(visible=False),&#10;                aspectmode='cube',&#10;                bgcolor='rgba(0,0,0,0.05)'&#10;            ),&#10;            title=dict(&#10;                text=f&quot;NEXAPod Network Globe - {self.num_nodes} Compute Nodes&quot;,&#10;                font=dict(size=16, color='#2c3e50'),&#10;                x=0.5&#10;            ),&#10;            width=800,&#10;            height=600,&#10;            margin=dict(t=60, b=10, l=10, r=10),&#10;            updatemenus=[{&#10;                &quot;buttons&quot;: [{&#10;                    &quot;args&quot;: [None, {&quot;frame&quot;: {&quot;duration&quot;: 50, &quot;redraw&quot;: True},&#10;                                    &quot;fromcurrent&quot;: True,&#10;                                    &quot;transition&quot;: {&quot;duration&quot;: 0}}],&#10;                    &quot;label&quot;: &quot;Play&quot;,&#10;                    &quot;method&quot;: &quot;animate&quot;&#10;                }, {&#10;                    &quot;args&quot;: [[None], {&quot;frame&quot;: {&quot;duration&quot;: 0, &quot;redraw&quot;: True},&#10;                                       &quot;mode&quot;: &quot;immediate&quot;,&#10;                                       &quot;transition&quot;: {&quot;duration&quot;: 0}}],&#10;                    &quot;label&quot;: &quot;Pause&quot;,&#10;                    &quot;method&quot;: &quot;animate&quot;&#10;                }],&#10;                &quot;direction&quot;: &quot;left&quot;,&#10;                &quot;pad&quot;: {&quot;r&quot;: 10, &quot;t&quot;: 70},&#10;                &quot;showactive&quot;: False,&#10;                &quot;type&quot;: &quot;buttons&quot;,&#10;                &quot;x&quot;: 0.1,&#10;                &quot;xanchor&quot;: &quot;right&quot;,&#10;                &quot;y&quot;: 0.02,&#10;                &quot;yanchor&quot;: &quot;top&quot;&#10;            }],&#10;            annotations=[{&#10;                'text': 'Fibonacci sphere distribution • Complete graph topology • JSON hover data',&#10;                'showarrow': False,&#10;                'xref': 'paper',&#10;                'yref': 'paper',&#10;                'x': 0.5,&#10;                'y': 0.02,&#10;                'xanchor': 'center',&#10;                'yanchor': 'bottom',&#10;                'font': {'size': 11, 'color': 'gray'}&#10;            }]&#10;        )&#10;&#10;        fig = go.Figure(data=data, layout=layout)&#10;        frames = self.generate_animation_frames()&#10;        fig.frames = frames&#10;        return fig&#10;&#10;&#10;class NEXAPodDashboard:&#10;    &quot;&quot;&quot;&#10;    Clean, streamlined NEXAPod Dashboard that displays key metrics,&#10;    data tables, and the 3D live network globe.&#10;    &quot;&quot;&quot;&#10;    def __init__(self):&#10;        self.initialize_session_state()&#10;&#10;    def initialize_session_state(self):&#10;        &quot;&quot;&quot;Initialize session state variables.&quot;&quot;&quot;&#10;        if 'nodes' not in st.session_state:&#10;            st.session_state.nodes = self.generate_demo_nodes(10)&#10;        if 'jobs' not in st.session_state:&#10;            st.session_state.jobs = self.generate_demo_jobs(6)&#10;        if 'last_update' not in st.session_state:&#10;            st.session_state.last_update = datetime.now()&#10;&#10;    def generate_demo_nodes(self, count: int) -&gt; List[Dict]:&#10;        &quot;&quot;&quot;Generate realistic demo node data.&quot;&quot;&quot;&#10;        tiers = ['CPU', 'CONSUMER_GPU', 'HPC']&#10;        statuses = ['Active', 'Busy', 'Maintenance', 'Offline']&#10;        regions = ['US-East', 'US-West', 'EU-Central', 'APAC', 'Americas']&#10;        nodes = []&#10;&#10;        for i in range(count):&#10;            tier = np.random.choice(tiers, p=[0.6, 0.3, 0.1])&#10;            status = np.random.choice(statuses, p=[0.7, 0.2, 0.07, 0.03])&#10;            node = {&#10;                'id': f&quot;node_{i:03d}&quot;,&#10;                'tier': tier,&#10;                'status': status,&#10;                'region': np.random.choice(regions),&#10;                'profile': {&#10;                    'cpu': f&quot;Intel Xeon E5-{2600 + i*10}&quot;,&#10;                    'cores': int(np.random.randint(8, 32)),&#10;                    'ram_gb': int(np.random.choice([16, 32, 64, 128])),&#10;                    'uptime_hours': int(np.random.randint(100, 8000))&#10;                },&#10;                'metrics': {&#10;                    'jobs_completed': int(np.random.randint(50, 800)),&#10;                    'cpu_usage': int(np.random.randint(20, 85)),&#10;                    'memory_usage': int(np.random.randint(25, 75)),&#10;                    'reputation_score': round(np.random.uniform(0.8, 1.0), 3),&#10;                    'credits_earned': round(np.random.uniform(500, 8000), 2)&#10;                }&#10;            }&#10;            nodes.append(node)&#10;        return nodes&#10;&#10;    def generate_demo_jobs(self, count: int) -&gt; List[Dict]:&#10;        &quot;&quot;&quot;Generate demo job data.&quot;&quot;&quot;&#10;        job_types = ['protein_folding', 'weather_simulation',&#10;                     'quantum_computation', 'materials_modeling',&#10;                     'ml_training', 'molecular_dynamics']&#10;        statuses = ['Queued', 'Running', 'Completed', 'Failed']&#10;        jobs = []&#10;&#10;        for i in range(count):&#10;            job_type = np.random.choice(job_types)&#10;            status = np.random.choice(statuses, p=[0.2, 0.3, 0.45, 0.05])&#10;            job = {&#10;                'id': f&quot;job_{i:04d}&quot;,&#10;                'type': job_type,&#10;                'status': status,&#10;                'submitter': f&quot;researcher_{chr(97+i%5)}&quot;,&#10;                'progress': int(np.random.randint(0, 100)) if status == 'Running' else (100 if status == 'Completed' else 0),&#10;                'credits_allocated': round(np.random.uniform(50, 500), 2),&#10;                'estimated_time': f&quot;{np.random.randint(30, 240)} min&quot;&#10;            }&#10;            jobs.append(job)&#10;        return jobs&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Main NEXAPod Dashboard application.&quot;&quot;&quot;&#10;    dashboard = NEXAPodDashboard()&#10;&#10;    st.markdown('&lt;h1 class=&quot;main-header&quot;&gt;NEXAPod Live Dashboard&lt;/h1&gt;', unsafe_allow_html=True)&#10;    st.markdown('&lt;p class=&quot;subtitle&quot;&gt;Distributed Compute Fabric for Scientific Problems&lt;/p&gt;', unsafe_allow_html=True)&#10;&#10;    # Sidebar controls&#10;    with st.sidebar:&#10;        st.header(&quot;Dashboard Controls&quot;)&#10;        st.subheader(&quot;Network Configuration&quot;)&#10;        node_count = st.slider(&quot;Number of Nodes&quot;, min_value=5, max_value=20, value=10)&#10;&#10;        if st.button(&quot;Regenerate Network&quot;):&#10;            st.session_state.nodes = dashboard.generate_demo_nodes(node_count)&#10;            st.rerun()&#10;&#10;        st.subheader(&quot;Filters&quot;)&#10;        tier_filter = st.multiselect(&#10;            &quot;Node Tiers&quot;,&#10;            options=['CPU', 'CONSUMER_GPU', 'HPC'],&#10;            default=['CPU', 'CONSUMER_GPU', 'HPC']&#10;        )&#10;        status_filter = st.multiselect(&#10;            &quot;Node Status&quot;,&#10;            options=['Active', 'Busy', 'Maintenance', 'Offline'],&#10;            default=['Active', 'Busy']&#10;        )&#10;&#10;        st.subheader(&quot;System Status&quot;)&#10;        st.write(&quot;**Coordinator:** Online&quot;)&#10;        st.write(&quot;**Database:** Connected&quot;)&#10;        st.write(f&quot;**Last Update:** {st.session_state.last_update.strftime('%H:%M:%S')}&quot;)&#10;&#10;        if st.button(&quot;Refresh Dashboard&quot;):&#10;            st.session_state.last_update = datetime.now()&#10;            st.rerun()&#10;&#10;    # Filter nodes&#10;    filtered_nodes = [&#10;        node for node in st.session_state.nodes&#10;        if node['tier'] in tier_filter and node['status'] in status_filter&#10;    ]&#10;&#10;    # Metrics row&#10;    col1, col2, col3, col4 = st.columns(4)&#10;    with col1:&#10;        active_nodes = len([n for n in filtered_nodes if n['status'] == 'Active'])&#10;        st.metric(&quot;Active Nodes&quot;, active_nodes, delta=f&quot;+{np.random.randint(0, 2)}&quot;)&#10;&#10;    with col2:&#10;        running_jobs = len([j for j in st.session_state.jobs if j['status'] == 'Running'])&#10;        st.metric(&quot;Running Jobs&quot;, running_jobs, delta=f&quot;+{np.random.randint(-1, 3)}&quot;)&#10;&#10;    with col3:&#10;        total_credits = sum(node['metrics']['credits_earned'] for node in filtered_nodes)&#10;        st.metric(&quot;Total Credits&quot;, f&quot;${total_credits:,.0f}&quot;, delta=f&quot;+${np.random.randint(100,500)}&quot;)&#10;&#10;    with col4:&#10;        utilization = np.random.randint(70, 95)&#10;        st.metric(&quot;Network Utilization&quot;, f&quot;{utilization}%&quot;, delta=f&quot;{np.random.randint(-3, 5)}%&quot;)&#10;&#10;    # Network Globe&#10;    st.header(&quot;Real-Time Network Globe&quot;)&#10;    st.markdown(&quot;&lt;p style='text-align:center; color:#e74c3c;'&gt;Disclaimer: This is demo data only&lt;/p&gt;&quot;, unsafe_allow_html=True)&#10;&#10;    if filtered_nodes:&#10;        display_nodes = filtered_nodes if len(filtered_nodes) != len(st.session_state.nodes) else st.session_state.nodes[:node_count]&#10;        globe_network = SpinningGlobeNetwork(display_nodes)&#10;        fig = globe_network.create_visualization()&#10;&#10;        config = {&#10;            'displayModeBar': True,&#10;            'displaylogo': False,&#10;            'modeBarButtonsToRemove': [&#10;                'pan3d', 'orbitRotation', 'tableRotation',&#10;                'resetCameraDefault3d', 'resetCameraLastSave3d'&#10;            ]&#10;        }&#10;        st.plotly_chart(fig, use_container_width=True, config=config)&#10;    else:&#10;        st.warning(&quot;No nodes match current filter criteria.&quot;)&#10;&#10;    # Data tables&#10;    col1, col2 = st.columns(2)&#10;&#10;    with col1:&#10;        st.subheader(&quot;Node Registry&quot;)&#10;        if filtered_nodes:&#10;            node_table_data = []&#10;            for node in filtered_nodes[:8]:&#10;                node_table_data.append({&#10;                    'ID': node['id'],&#10;                    'Tier': node['tier'],&#10;                    'Status': node['status'],&#10;                    'Region': node['region'],&#10;                    'Jobs': node['metrics']['jobs_completed'],&#10;                    'Credits': f&quot;${node['metrics']['credits_earned']:.0f}&quot;,&#10;                    'Reputation': f&quot;{node['metrics']['reputation_score']:.3f}&quot;&#10;                })&#10;            st.dataframe(node_table_data, use_container_width=True)&#10;&#10;            st.write(&quot;**Node Distribution:**&quot;)&#10;            tier_counts = {}&#10;            for node in filtered_nodes:&#10;                tier_counts[node['tier']] = tier_counts.get(node['tier'], 0) + 1&#10;            for tier, count in tier_counts.items():&#10;                st.write(f&quot;• {tier}: {count} nodes&quot;)&#10;&#10;    with col2:&#10;        st.subheader(&quot;Job Queue Status&quot;)&#10;        if st.session_state.jobs:&#10;            job_table_data = []&#10;            for job in st.session_state.jobs:&#10;                job_table_data.append({&#10;                    'ID': job['id'],&#10;                    'Type': job['type'].replace('_', ' ').title(),&#10;                    'Status': job['status'],&#10;                    'Progress': f&quot;{job['progress']}%&quot; if job['status'] == 'Running' else '—',&#10;                    'Credits': f&quot;${job['credits_allocated']:.0f}&quot;,&#10;                    'Time Est.': job.get('estimated_time', '—'),&#10;                    'Submitter': job['submitter']&#10;                })&#10;            st.dataframe(job_table_data, use_container_width=True)&#10;&#10;            st.write(&quot;**Job Distribution:**&quot;)&#10;            status_counts = {}&#10;            for job in st.session_state.jobs:&#10;                status_counts[job['status']] = status_counts.get(job['status'], 0) + 1&#10;            for status, count in status_counts.items():&#10;                st.write(f&quot;• {status}: {count} jobs&quot;)&#10;&#10;    # Performance metrics&#10;    st.header(&quot;System Performance&quot;)&#10;    col1, col2, col3 = st.columns(3)&#10;&#10;    with col1:&#10;        st.subheader(&quot;Compute Metrics&quot;)&#10;        st.write(f&quot;**Total FLOPS:** {np.random.uniform(500,2000):.1f} TFLOPS&quot;)&#10;        st.write(f&quot;**Average Job Time:** {np.random.randint(45,180)} minutes&quot;)&#10;        st.write(f&quot;**Success Rate:** {np.random.uniform(96,99.5):.1f}%&quot;)&#10;        st.write(f&quot;**Queue Wait:** {np.random.randint(2,12)} minutes&quot;)&#10;&#10;    with col2:&#10;        st.subheader(&quot;Resource Usage&quot;)&#10;        st.write(f&quot;**CPU Utilization:** {np.random.randint(60,85)}%&quot;)&#10;        st.write(f&quot;**Memory Usage:** {np.random.randint(55,80)}%&quot;)&#10;        st.write(f&quot;**Network I/O:** {np.random.uniform(15,45):.1f} Gbps&quot;)&#10;        st.write(f&quot;**Storage I/O:** {np.random.uniform(5,25):.1f} GB/s&quot;)&#10;&#10;    with col3:&#10;        st.subheader(&quot;Economic Data&quot;)&#10;        st.write(f&quot;**Credits/Hour:** ${np.random.uniform(75,250):.0f}&quot;)&#10;        st.write(f&quot;**Daily Volume:** ${np.random.uniform(5000,15000):.0f}&quot;)&#10;        st.write(f&quot;**Avg Rate:** ${np.random.uniform(15,35):.2f}/job&quot;)&#10;        if filtered_nodes:&#10;            st.write(f&quot;**Top Earner:** ${max(n['metrics']['credits_earned'] for n in filtered_nodes):.0f}&quot;)&#10;&#10;    # Footer&#10;    st.markdown(&quot;---&quot;)&#10;    col1, col2, col3 = st.columns(3)&#10;&#10;    with col1:&#10;        st.write(&quot;**System Status:** All systems operational&quot;)&#10;    with col2:&#10;        st.write(&quot;**API Endpoint:** http://localhost:5000&quot;)&#10;    with col3:&#10;        if st.button(&quot;Export Report&quot;):&#10;            st.success(&quot;System report exported&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="import json&#10;from datetime import datetime&#10;from typing import List, Dict, Tuple&#10;&#10;import networkx as nx&#10;import numpy as np&#10;import plotly.graph_objects as go&#10;import streamlit as st&#10;&#10;st.set_page_config(&#10;    page_title=&quot;NEXAPod Dashboard&quot;,&#10;    page_icon=&quot;&quot;,&#10;    layout=&quot;wide&quot;,&#10;    initial_sidebar_state=&quot;expanded&quot;&#10;)&#10;&#10;st.markdown(&quot;&quot;&quot;&#10;&lt;style&gt;&#10;    .main-header {&#10;        font-size: 2.5rem;&#10;        font-weight: bold;&#10;        color: #2c3e50;&#10;        text-align: center;&#10;        margin-bottom: 1rem;&#10;    }&#10;    .subtitle {&#10;        text-align: center;&#10;        color: #7f8c8d;&#10;        font-size: 1.1rem;&#10;        margin-bottom: 2rem;&#10;    }&#10;    .metric-container {&#10;        background: #f8f9fa;&#10;        border: 1px solid #e9ecef;&#10;        border-radius: 8px;&#10;        padding: 1rem;&#10;        margin: 0.5rem 0;&#10;    }&#10;    .status-active { color: #27ae60; font-weight: bold; }&#10;    .status-busy { color: #f39c12; font-weight: bold; }&#10;    .status-offline { color: #e74c3c; font-weight: bold; }&#10;    .status-maintenance { color: #8e44ad; font-weight: bold; }&#10;    .sidebar-section {&#10;        background-color: #f8f9fa;&#10;        padding: 1rem;&#10;        border-radius: 6px;&#10;        margin: 1rem 0;&#10;        border-left: 3px solid #3498db;&#10;    }&#10;    .data-table {&#10;        font-size: 0.9rem;&#10;    }&#10;&lt;/style&gt;&#10;&quot;&quot;&quot;, unsafe_allow_html=True)&#10;&#10;&#10;class SpinningGlobeNetwork:&#10;    &quot;&quot;&quot;&#10;    3D Spinning Globe Network Visualization&#10;&#10;    Creates an interactive 3D visualization of a complete graph&#10;    network with nodes distributed on a sphere using a Fibonacci&#10;    spiral. Nodes use larger markers and show single-line JSON hover&#10;    information. Live animation rotates the globe and pulses nodes.&#10;    &quot;&quot;&quot;&#10;    def __init__(self, nodes_data: List[Dict]):&#10;        self.nodes_data = nodes_data&#10;        self.num_nodes = len(nodes_data)&#10;&#10;    def fibonacci_sphere_distribution(&#10;            self) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:&#10;        &quot;&quot;&quot;Generate optimal node positions using Fibonacci spiral.&quot;&quot;&quot;&#10;        n = self.num_nodes&#10;        indices = np.arange(n) + 0.5&#10;        phi = np.arccos(1 - 2 * (indices / n))&#10;        theta = np.pi * (1 + np.sqrt(5)) * indices&#10;        x = np.sin(phi) * np.cos(theta)&#10;        y = np.sin(phi) * np.sin(theta)&#10;        z = np.cos(phi)&#10;        return x, y, z&#10;&#10;    @staticmethod&#10;    def create_sphere_surface(resolution: int = 50) -&gt; go.Surface:&#10;        &quot;&quot;&quot;Create the background sphere surface.&quot;&quot;&quot;&#10;        u = np.linspace(0, np.pi, resolution)&#10;        v = np.linspace(0, 2 * np.pi, resolution)&#10;        U, V = np.meshgrid(u, v)&#10;        X_sphere = np.sin(U) * np.cos(V)&#10;        Y_sphere = np.sin(U) * np.sin(V)&#10;        Z_sphere = np.cos(U)&#10;        return go.Surface(&#10;            x=X_sphere, y=Y_sphere, z=Z_sphere,&#10;            colorscale='Viridis',&#10;            opacity=0.5,&#10;            showscale=False,&#10;            hoverinfo='skip'&#10;        )&#10;&#10;    def create_network_edges(&#10;            self, node_positions: Tuple[np.ndarray, ...]) -&gt; List[go.Scatter3d]:&#10;        &quot;&quot;&quot;Create edge traces for complete graph connectivity.&quot;&quot;&quot;&#10;        x_coords, y_coords, z_coords = node_positions&#10;        G = nx.complete_graph(self.num_nodes)&#10;        edge_traces = []&#10;        for edge in G.edges():&#10;            i, j = edge&#10;            edge_trace = go.Scatter3d(&#10;                x=[x_coords[i], x_coords[j]],&#10;                y=[y_coords[i], y_coords[j]],&#10;                z=[z_coords[i], z_coords[j]],&#10;                mode='lines',&#10;                line=dict(color='rgba(100, 149, 237, 0.6)', width=2),&#10;                hoverinfo='skip',&#10;                showlegend=False&#10;            )&#10;            edge_traces.append(edge_trace)&#10;        return edge_traces&#10;&#10;    def prepare_hover_information(self) -&gt; List[str]:&#10;        &quot;&quot;&quot;&#10;        Prepare JSON-formatted hover text for each node in a single-line format.&#10;        &quot;&quot;&quot;&#10;        hover_texts = []&#10;        for node in self.nodes_data:&#10;            hover_data = {&#10;                'id': node['id'],&#10;                'tier': node['tier'],&#10;                'status': node['status'],&#10;                'region': node['region'],&#10;                'cpu_usage': f&quot;{node['metrics']['cpu_usage']}%&quot;,&#10;                'memory_usage': f&quot;{node['metrics']['memory_usage']}%&quot;,&#10;                'jobs_completed': node['metrics']['jobs_completed'],&#10;                'reputation_score': node['metrics']['reputation_score'],&#10;                'credits_earned':&#10;                    f&quot;${node['metrics']['credits_earned']:.2f}&quot;,&#10;                'uptime_hours': node['profile']['uptime_hours']&#10;            }&#10;            hover_text = json.dumps(hover_data)&#10;            hover_texts.append(hover_text)&#10;        return hover_texts&#10;&#10;    def create_node_trace(self, node_positions: Tuple[np.ndarray, ...]) -&gt; go.Scatter3d:&#10;        &quot;&quot;&quot;Create the main node scatter trace with larger markers.&quot;&quot;&quot;&#10;        x_coords, y_coords, z_coords = node_positions&#10;        hover_texts = self.prepare_hover_information()&#10;        return go.Scatter3d(&#10;            x=x_coords, y=y_coords, z=z_coords,&#10;            mode='markers+text',&#10;            marker=dict(&#10;                symbol='circle',&#10;                size=[12] * self.num_nodes,&#10;                color='red',&#10;                line=dict(width=2, color='white'),&#10;                opacity=0.9&#10;            ),&#10;            text=[f&quot;Node {i}&quot; for i in range(self.num_nodes)],&#10;            textposition='middle center',&#10;            textfont=dict(size=10, color='white'),&#10;            hovertext=hover_texts,&#10;            hoverinfo='text',&#10;            showlegend=False&#10;        )&#10;&#10;    def generate_animation_frames(self, num_frames: int = 60) -&gt; List[Dict]:&#10;        &quot;&quot;&quot;&#10;        Generate animation frames for camera rotation and node pulsing.&#10;        &quot;&quot;&quot;&#10;        frames = []&#10;        phases = [2 * np.pi * j / self.num_nodes for j in range(self.num_nodes)]&#10;        for i in range(num_frames):&#10;            angle = 2 * np.pi * i / num_frames&#10;            cam_eye = dict(x=2 * np.cos(angle), y=2 * np.sin(angle), z=0.5)&#10;            node_sizes = [&#10;                12 + 3 * ((np.sin(&#10;                    2 * np.pi * i / num_frames + phases[j]) + 1) / 2)&#10;                for j in range(self.num_nodes)&#10;            ]&#10;            frame = dict(&#10;                data=[dict(marker=dict(size=node_sizes))],&#10;                traces=[1],&#10;                layout=dict(scene=dict(camera=dict(eye=cam_eye)))&#10;            )&#10;            frames.append(frame)&#10;        return frames&#10;&#10;    def create_visualization(self) -&gt; go.Figure:&#10;        &quot;&quot;&quot;Create the complete 3D spinning globe network visualization.&quot;&quot;&quot;&#10;        node_positions = self.fibonacci_sphere_distribution()&#10;        sphere_trace = self.create_sphere_surface()&#10;        node_trace = self.create_node_trace(node_positions)&#10;        edge_traces = self.create_network_edges(node_positions)&#10;        data = [sphere_trace, node_trace] + edge_traces&#10;&#10;        layout = dict(&#10;            scene=dict(&#10;                xaxis=dict(visible=False),&#10;                yaxis=dict(visible=False),&#10;                zaxis=dict(visible=False),&#10;                aspectmode='cube',&#10;                bgcolor='rgba(0,0,0,0.05)'&#10;            ),&#10;            title=dict(&#10;                text=f&quot;NEXAPod Network Globe - {self.num_nodes} &quot;&#10;                     f&quot;Compute Nodes&quot;,&#10;                font=dict(size=16, color='#2c3e50'),&#10;                x=0.5&#10;            ),&#10;            width=800,&#10;            height=600,&#10;            margin=dict(t=60, b=10, l=10, r=10),&#10;            updatemenus=[{&#10;                &quot;buttons&quot;: [{&#10;                    &quot;args&quot;: [None, {&quot;frame&quot;: {&quot;duration&quot;: 50, &quot;redraw&quot;: True},&#10;                                    &quot;fromcurrent&quot;: True,&#10;                                    &quot;transition&quot;: {&quot;duration&quot;: 0}}],&#10;                    &quot;label&quot;: &quot;Play&quot;,&#10;                    &quot;method&quot;: &quot;animate&quot;&#10;                }, {&#10;                    &quot;args&quot;: [[None], {&quot;frame&quot;: {&quot;duration&quot;: 0, &quot;redraw&quot;: True},&#10;                                     &quot;mode&quot;: &quot;immediate&quot;,&#10;                                     &quot;transition&quot;: {&quot;duration&quot;: 0}}],&#10;                    &quot;label&quot;: &quot;Pause&quot;,&#10;                    &quot;method&quot;: &quot;animate&quot;&#10;                }],&#10;                &quot;direction&quot;: &quot;left&quot;,&#10;                &quot;pad&quot;: {&quot;r&quot;: 10, &quot;t&quot;: 70},&#10;                &quot;showactive&quot;: False,&#10;                &quot;type&quot;: &quot;buttons&quot;,&#10;                &quot;x&quot;: 0.1,&#10;                &quot;xanchor&quot;: &quot;right&quot;,&#10;                &quot;y&quot;: 0.02,&#10;                &quot;yanchor&quot;: &quot;top&quot;&#10;            }],&#10;            annotations=[{&#10;                'text': 'Fibonacci sphere distribution • Complete graph '&#10;                        'topology • JSON hover data',&#10;                'showarrow': False,&#10;                'xref': 'paper',&#10;                'yref': 'paper',&#10;                'x': 0.5,&#10;                'y': 0.02,&#10;                'xanchor': 'center',&#10;                'yanchor': 'bottom',&#10;                'font': {'size': 11, 'color': 'gray'}&#10;            }]&#10;        )&#10;&#10;        fig = go.Figure(data=data, layout=layout)&#10;        frames = self.generate_animation_frames()&#10;        fig.frames = frames&#10;        return fig&#10;&#10;&#10;class NEXAPodDashboard:&#10;    &quot;&quot;&quot;&#10;    Clean, streamlined NEXAPod Dashboard that displays key metrics,&#10;    data tables, and the 3D live network globe.&#10;    &quot;&quot;&quot;&#10;    def __init__(self):&#10;        self.initialize_session_state()&#10;&#10;    def initialize_session_state(self):&#10;        &quot;&quot;&quot;Initialize session state variables.&quot;&quot;&quot;&#10;        if 'nodes' not in st.session_state:&#10;            st.session_state.nodes = self.generate_demo_nodes(10)&#10;        if 'jobs' not in st.session_state:&#10;            st.session_state.jobs = self.generate_demo_jobs(6)&#10;        if 'last_update' not in st.session_state:&#10;            st.session_state.last_update = datetime.now()&#10;&#10;    def generate_demo_nodes(self, count: int) -&gt; List[Dict]:&#10;        &quot;&quot;&quot;Generate realistic demo node data.&quot;&quot;&quot;&#10;        tiers = ['CPU', 'CONSUMER_GPU', 'HPC']&#10;        statuses = ['Active', 'Busy', 'Maintenance', 'Offline']&#10;        regions = ['US-East', 'US-West', 'EU-Central', 'APAC', 'Americas']&#10;        nodes = []&#10;&#10;        for i in range(count):&#10;            tier = np.random.choice(tiers, p=[0.6, 0.3, 0.1])&#10;            status = np.random.choice(statuses, p=[0.7, 0.2, 0.07, 0.03])&#10;            node = {&#10;                'id': f&quot;node_{i:03d}&quot;,&#10;                'tier': tier,&#10;                'status': status,&#10;                'region': np.random.choice(regions),&#10;                'profile': {&#10;                    'cpu': f&quot;Intel Xeon E5-{2600 + i*10}&quot;,&#10;                    'cores': int(np.random.randint(8, 32)),&#10;                    'ram_gb': int(np.random.choice([16, 32, 64, 128])),&#10;                    'uptime_hours': int(np.random.randint(100, 8000))&#10;                },&#10;                'metrics': {&#10;                    'jobs_completed': int(np.random.randint(50, 800)),&#10;                    'cpu_usage': int(np.random.randint(20, 85)),&#10;                    'memory_usage': int(np.random.randint(25, 75)),&#10;                    'reputation_score': round(np.random.uniform(0.8, 1.0), 3),&#10;                    'credits_earned': round(np.random.uniform(500, 8000), 2)&#10;                }&#10;            }&#10;            nodes.append(node)&#10;        return nodes&#10;&#10;    def generate_demo_jobs(self, count: int) -&gt; List[Dict]:&#10;        &quot;&quot;&quot;Generate demo job data.&quot;&quot;&quot;&#10;        job_types = ['protein_folding', 'weather_simulation',&#10;                     'quantum_computation', 'materials_modeling',&#10;                     'ml_training', 'molecular_dynamics']&#10;        statuses = ['Queued', 'Running', 'Completed', 'Failed']&#10;        jobs = []&#10;&#10;        for i in range(count):&#10;            job_type = np.random.choice(job_types)&#10;            status = np.random.choice(statuses, p=[0.2, 0.3, 0.45, 0.05])&#10;            job = {&#10;                'id': f&quot;job_{i:04d}&quot;,&#10;                'type': job_type,&#10;                'status': status,&#10;                'submitter': f&quot;researcher_{chr(97+i%5)}&quot;,&#10;                'progress': int(np.random.randint(0, 100)) if status == 'Running' else (100 if status == 'Completed' else 0),&#10;                'credits_allocated': round(np.random.uniform(50, 500), 2),&#10;                'estimated_time': f&quot;{np.random.randint(30, 240)} min&quot;&#10;            }&#10;            jobs.append(job)&#10;        return jobs&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Main NEXAPod Dashboard application.&quot;&quot;&quot;&#10;    dashboard = NEXAPodDashboard()&#10;&#10;    st.markdown('&lt;h1 class=&quot;main-header&quot;&gt;NEXAPod Live Dashboard&lt;/h1&gt;',&#10;                unsafe_allow_html=True)&#10;    st.markdown('&lt;p class=&quot;subtitle&quot;&gt;Distributed Compute Fabric for '&#10;                'Scientific Problems&lt;/p&gt;', unsafe_allow_html=True)&#10;&#10;    # Sidebar controls&#10;    with st.sidebar:&#10;        st.header(&quot;Dashboard Controls&quot;)&#10;        st.subheader(&quot;Network Configuration&quot;)&#10;        node_count = st.slider(&quot;Number of Nodes&quot;, min_value=5, max_value=20, value=10)&#10;&#10;        if st.button(&quot;Regenerate Network&quot;):&#10;            st.session_state.nodes = dashboard.generate_demo_nodes(node_count)&#10;            st.rerun()&#10;&#10;        st.subheader(&quot;Filters&quot;)&#10;        tier_filter = st.multiselect(&#10;            &quot;Node Tiers&quot;,&#10;            options=['CPU', 'CONSUMER_GPU', 'HPC'],&#10;            default=['CPU', 'CONSUMER_GPU', 'HPC']&#10;        )&#10;        status_filter = st.multiselect(&#10;            &quot;Node Status&quot;,&#10;            options=['Active', 'Busy', 'Maintenance', 'Offline'],&#10;            default=['Active', 'Busy']&#10;        )&#10;&#10;        st.subheader(&quot;System Status&quot;)&#10;        st.write(&quot;**Coordinator:** Online&quot;)&#10;        st.write(&quot;**Database:** Connected&quot;)&#10;        st.write(f&quot;**Last Update:** {st.session_state.last_update.strftime('%H:%M:%S')}&quot;)&#10;&#10;        if st.button(&quot;Refresh Dashboard&quot;):&#10;            st.session_state.last_update = datetime.now()&#10;            st.rerun()&#10;&#10;    # Filter nodes&#10;    filtered_nodes = [&#10;        node for node in st.session_state.nodes&#10;        if node['tier'] in tier_filter and node['status'] in status_filter&#10;    ]&#10;&#10;    # Metrics row&#10;    col1, col2, col3, col4 = st.columns(4)&#10;    with col1:&#10;        active_nodes = len([n for n in filtered_nodes if n['status'] == 'Active'])&#10;        st.metric(&quot;Active Nodes&quot;, active_nodes, delta=f&quot;+{np.random.randint(0, 2)}&quot;)&#10;&#10;    with col2:&#10;        running_jobs = len([j for j in st.session_state.jobs if j['status'] == 'Running'])&#10;        st.metric(&quot;Running Jobs&quot;, running_jobs, delta=f&quot;+{np.random.randint(-1, 3)}&quot;)&#10;&#10;    with col3:&#10;        total_credits = sum(node['metrics']['credits_earned'] for node in filtered_nodes)&#10;        st.metric(&quot;Total Credits&quot;, f&quot;${total_credits:,.0f}&quot;, delta=f&quot;+${np.random.randint(100,500)}&quot;)&#10;&#10;    with col4:&#10;        utilization = np.random.randint(70, 95)&#10;        st.metric(&quot;Network Utilization&quot;, f&quot;{utilization}%&quot;, delta=f&quot;{np.random.randint(-3, 5)}%&quot;)&#10;&#10;    # Network Globe&#10;    st.header(&quot;Real-Time Network Globe&quot;)&#10;    st.markdown(&quot;&lt;p style='text-align:center; color:#e74c3c;'&gt;Disclaimer: &quot;&#10;                &quot;This is demo data only&lt;/p&gt;&quot;, unsafe_allow_html=True)&#10;&#10;    if filtered_nodes:&#10;        if len(filtered_nodes) != len(st.session_state.nodes):&#10;            display_nodes = filtered_nodes&#10;        else:&#10;            display_nodes = st.session_state.nodes[:node_count]&#10;        globe_network = SpinningGlobeNetwork(display_nodes)&#10;        fig = globe_network.create_visualization()&#10;&#10;        config = {&#10;            'displayModeBar': True,&#10;            'displaylogo': False,&#10;            'modeBarButtonsToRemove': [&#10;                'pan3d', 'orbitRotation', 'tableRotation',&#10;                'resetCameraDefault3d', 'resetCameraLastSave3d'&#10;            ]&#10;        }&#10;        st.plotly_chart(fig, use_container_width=True, config=config)&#10;    else:&#10;        st.warning(&quot;No nodes match current filter criteria.&quot;)&#10;&#10;    # Data tables&#10;    col1, col2 = st.columns(2)&#10;&#10;    with col1:&#10;        st.subheader(&quot;Node Registry&quot;)&#10;        if filtered_nodes:&#10;            node_table_data = []&#10;            for node in filtered_nodes[:8]:&#10;                node_table_data.append({&#10;                    'ID': node['id'],&#10;                    'Tier': node['tier'],&#10;                    'Status': node['status'],&#10;                    'Region': node['region'],&#10;                    'Jobs': node['metrics']['jobs_completed'],&#10;                    'Credits': f&quot;${node['metrics']['credits_earned']:.0f}&quot;,&#10;                    'Reputation': f&quot;{node['metrics']['reputation_score']:.3f}&quot;&#10;                })&#10;            st.dataframe(node_table_data, use_container_width=True)&#10;&#10;            st.write(&quot;**Node Distribution:**&quot;)&#10;            tier_counts = {}&#10;            for node in filtered_nodes:&#10;                tier_counts[node['tier']] = tier_counts.get(node['tier'], 0) + 1&#10;            for tier, count in tier_counts.items():&#10;                st.write(f&quot;• {tier}: {count} nodes&quot;)&#10;&#10;    with col2:&#10;        st.subheader(&quot;Job Queue Status&quot;)&#10;        if st.session_state.jobs:&#10;            job_table_data = []&#10;            for job in st.session_state.jobs:&#10;                job_table_data.append({&#10;                    'ID': job['id'],&#10;                    'Type': job['type'].replace('_', ' ').title(),&#10;                    'Status': job['status'],&#10;                    'Progress': f&quot;{job['progress']}%&quot;&#10;                    if job['status'] == 'Running' else '—',&#10;                    'Credits': f&quot;${job['credits_allocated']:.0f}&quot;,&#10;                    'Time Est.': job.get('estimated_time', '—'),&#10;                    'Submitter': job['submitter']&#10;                })&#10;            st.dataframe(job_table_data, use_container_width=True)&#10;&#10;            st.write(&quot;**Job Distribution:**&quot;)&#10;            status_counts = {}&#10;            for job in st.session_state.jobs:&#10;                status_counts[job['status']] = status_counts.get(job['status'], 0) + 1&#10;            for status, count in status_counts.items():&#10;                st.write(f&quot;• {status}: {count} jobs&quot;)&#10;&#10;    # Performance metrics&#10;    st.header(&quot;System Performance&quot;)&#10;    col1, col2, col3 = st.columns(3)&#10;&#10;    with col1:&#10;        st.subheader(&quot;Compute Metrics&quot;)&#10;        st.write(f&quot;**Total FLOPS:** {np.random.uniform(500,2000):.1f} TFLOPS&quot;)&#10;        st.write(f&quot;**Average Job Time:** {np.random.randint(45,180)} minutes&quot;)&#10;        st.write(f&quot;**Success Rate:** {np.random.uniform(96,99.5):.1f}%&quot;)&#10;        st.write(f&quot;**Queue Wait:** {np.random.randint(2,12)} minutes&quot;)&#10;&#10;    with col2:&#10;        st.subheader(&quot;Resource Usage&quot;)&#10;        st.write(f&quot;**CPU Utilization:** {np.random.randint(60,85)}%&quot;)&#10;        st.write(f&quot;**Memory Usage:** {np.random.randint(55,80)}%&quot;)&#10;        st.write(f&quot;**Network I/O:** {np.random.uniform(15,45):.1f} Gbps&quot;)&#10;        st.write(f&quot;**Storage I/O:** {np.random.uniform(5,25):.1f} GB/s&quot;)&#10;&#10;    with col3:&#10;        st.subheader(&quot;Economic Data&quot;)&#10;        st.write(f&quot;**Credits/Hour:** ${np.random.uniform(75,250):.0f}&quot;)&#10;        st.write(f&quot;**Daily Volume:** ${np.random.uniform(5000,15000):.0f}&quot;)&#10;        st.write(f&quot;**Avg Rate:** ${np.random.uniform(15,35):.2f}/job&quot;)&#10;        if filtered_nodes:&#10;            credits = [n['metrics']['credits_earned'] for n in filtered_nodes]&#10;            st.write(f&quot;**Top Earner:** ${max(credits):.0f}&quot;)&#10;&#10;    # Footer&#10;    st.markdown(&quot;---&quot;)&#10;    col1, col2, col3 = st.columns(3)&#10;&#10;    with col1:&#10;        st.write(&quot;**System Status:** All systems operational&quot;)&#10;    with col2:&#10;        st.write(&quot;**API Endpoint:** http://localhost:5000&quot;)&#10;    with col3:&#10;        if st.button(&quot;Export Report&quot;):&#10;            st.success(&quot;System report exported&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Client/descriptor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Client/descriptor.py" />
              <option name="originalContent" value="from dataclasses import dataclass, field&#10;from typing import Any, Callable, Dict, List&#10;&#10;@dataclass&#10;class JobDescriptor:&#10;    &quot;&quot;&quot;Descriptor for job configuration and validation.&quot;&quot;&quot;&#10;    id: str&#10;    image: str&#10;    compute_estimate: float&#10;    inputs: Dict[str, str]&#10;    outputs: Dict[str, str]&#10;    checker: Callable[[Dict[str, Any]], bool] = field(default=lambda out: True)&#10;    tags: List[str] = field(default_factory=list)&#10;" />
              <option name="updatedContent" value="from dataclasses import dataclass, field&#13;&#10;from typing import Any, Callable, Dict, List&#13;&#10;&#13;&#10;&#13;&#10;@dataclass&#13;&#10;class JobDescriptor:&#13;&#10;    &quot;&quot;&quot;Descriptor for job configuration and validation.&quot;&quot;&quot;&#13;&#10;    id: str&#13;&#10;    image: str&#13;&#10;    compute_estimate: float&#13;&#10;    inputs: Dict[str, str]&#13;&#10;    outputs: Dict[str, str]&#13;&#10;    checker: Callable[[Dict[str, Any]], bool] = field(default=lambda out: True)&#13;&#10;    tags: List[str] = field(default_factory=list)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Client/executor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Client/executor.py" />
              <option name="originalContent" value="import tempfile&#10;import docker&#10;&#10;&#10;def execute_job(job: dict) -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Pull Docker image, prepare inputs, run container, and return&#10;    execution result.&#10;    &quot;&quot;&quot;&#10;    client = docker.from_env()&#10;    image = job['docker_image']&#10;    job_id = job['job_id']&#10;    client.images.pull(image)&#10;    input_dir = tempfile.mkdtemp(prefix=f&quot;nexapod_{job_id}_&quot;)&#10;    for input_file in job.get('input_files', []):&#10;        path = f&quot;{input_dir}/{input_file['name']}&quot;&#10;        with open(path, 'wb') as f:&#10;            f.write(input_file['content'])&#10;    output = client.containers.run(&#10;        image,&#10;        volumes={input_dir: {'bind': '/inputs', 'mode': 'rw'}},&#10;        remove=True&#10;    )&#10;    return {&#10;        'job_id': job_id,&#10;        'output': output.decode() if isinstance(output, bytes) else str(output),&#10;        'status': 'completed'&#10;    }&#10;" />
              <option name="updatedContent" value="import tempfile&#13;&#10;import docker&#13;&#10;&#13;&#10;&#13;&#10;def execute_job(job: dict) -&gt; dict:&#13;&#10;    &quot;&quot;&quot;&#13;&#10;    Pull Docker image, prepare inputs, run container, and return&#13;&#10;    execution result.&#13;&#10;    &quot;&quot;&quot;&#13;&#10;    client = docker.from_env()&#13;&#10;    image = job['docker_image']&#13;&#10;    job_id = job['job_id']&#13;&#10;    client.images.pull(image)&#13;&#10;    input_dir = tempfile.mkdtemp(prefix=f&quot;nexapod_{job_id}_&quot;)&#13;&#10;    for input_file in job.get('input_files', []):&#13;&#10;        path = f&quot;{input_dir}/{input_file['name']}&quot;&#13;&#10;        with open(path, 'wb') as f:&#13;&#10;            f.write(input_file['content'])&#13;&#10;    output = client.containers.run(&#13;&#10;        image,&#13;&#10;        volumes={input_dir: {'bind': '/inputs', 'mode': 'rw'}},&#13;&#10;        remove=True&#13;&#10;    )&#13;&#10;    return {&#13;&#10;        'job_id': job_id,&#13;&#10;        'output': (output.decode() if isinstance(output, bytes)&#13;&#10;                   else str(output)),&#13;&#10;        'status': 'completed'&#13;&#10;    }" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Client/logger.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Client/logger.py" />
              <option name="originalContent" value="import json&#10;import hashlib&#10;import os&#10;import time&#10;from cryptography.hazmat.primitives import serialization&#10;from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey&#10;&#10;&#10;def load_private_key(path: str) -&gt; Ed25519PrivateKey:&#10;    &quot;&quot;&quot;Load and return an Ed25519 private key from the given path.&quot;&quot;&quot;&#10;    with open(os.path.expanduser(path), 'rb') as f:&#10;        return Ed25519PrivateKey.from_private_bytes(f.read())&#10;&#10;&#10;def log_result(result: dict, config: dict):&#10;    &quot;&quot;&quot;Sign, hash, timestamp, and persist the job result.&quot;&quot;&quot;&#10;    result['timestamp'] = int(time.time())&#10;    result_json = json.dumps(result, sort_keys=True)&#10;    result['sha256'] = hashlib.sha256(result_json.encode()).hexdigest()&#10;    key = load_private_key(config['private_key_path'])&#10;    result['signature'] = key.sign(result_json.encode()).hex()&#10;    log_path = f&quot;nexapod_{result['job_id']}_log.json&quot;&#10;    with open(log_path, 'w') as f:&#10;        json.dump(result, f, indent=2)&#10;    print(f&quot;Result logged and signed: {log_path}&quot;)&#10;" />
              <option name="updatedContent" value="import json&#13;&#10;import hashlib&#13;&#10;import os&#13;&#10;import time&#13;&#10;from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey&#13;&#10;&#13;&#10;&#13;&#10;def load_private_key(path: str) -&gt; Ed25519PrivateKey:&#13;&#10;    &quot;&quot;&quot;Load and return an Ed25519 private key from the given path.&quot;&quot;&quot;&#13;&#10;    with open(os.path.expanduser(path), 'rb') as f:&#13;&#10;        return Ed25519PrivateKey.from_private_bytes(f.read())&#13;&#10;&#13;&#10;&#13;&#10;def log_result(result: dict, config: dict):&#13;&#10;    &quot;&quot;&quot;Sign, hash, timestamp, and persist the job result.&quot;&quot;&quot;&#13;&#10;    result['timestamp'] = int(time.time())&#13;&#10;    result_json = json.dumps(result, sort_keys=True)&#13;&#10;    result['sha256'] = hashlib.sha256(result_json.encode()).hexdigest()&#13;&#10;    key = load_private_key(config['private_key_path'])&#13;&#10;    result['signature'] = key.sign(result_json.encode()).hex()&#13;&#10;    log_path = f&quot;nexapod_{result['job_id']}_log.json&quot;&#13;&#10;    with open(log_path, 'w') as f:&#13;&#10;        json.dump(result, f, indent=2)&#13;&#10;    print(f&quot;Result logged and signed: {log_path}&quot;)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Client/profiles.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Client/profiles.py" />
              <option name="originalContent" value="import platform&#10;import psutil&#10;import subprocess&#10;&#10;&#10;def get_node_profile() -&gt; dict:&#10;    &quot;&quot;&quot;&#10;    Collect system profile including CPU, cores, threads, RAM, OS, and GPU info.&#10;    &quot;&quot;&quot;&#10;    profile = {&#10;        'cpu': platform.processor(),&#10;        'cores': psutil.cpu_count(logical=False),&#10;        'threads': psutil.cpu_count(logical=True),&#10;        'ram_gb': round(psutil.virtual_memory().total / 1e9, 2),&#10;        'os': platform.system(),&#10;        'gpu': None&#10;    }&#10;    try:&#10;        result = subprocess.run(&#10;            [&#10;                'nvidia-smi',&#10;                '--query-gpu=name,memory.total',&#10;                '--format=csv,noheader'&#10;            ],&#10;            capture_output=True,&#10;            text=True,&#10;            check=True&#10;        )&#10;        gpus = []&#10;        for line in result.stdout.strip().split('\n'):&#10;            name, mem = line.split(',')&#10;            gpus.append({&#10;                'name': name.strip(),&#10;                'memory_gb': float(mem.strip().split()[0]) / 1024&#10;            })&#10;        profile['gpu'] = gpus&#10;    except subprocess.SubprocessError:&#10;        profile['gpu'] = []&#10;    return profile&#10;" />
              <option name="updatedContent" value="import platform&#13;&#10;import psutil&#13;&#10;import subprocess&#13;&#10;&#13;&#10;&#13;&#10;def get_node_profile() -&gt; dict:&#13;&#10;    &quot;&quot;&quot;&#13;&#10;    Collect system profile including CPU, cores, threads, RAM, OS, and GPU.&#13;&#10;    &quot;&quot;&quot;&#13;&#10;    profile = {&#13;&#10;        'cpu': platform.processor(),&#13;&#10;        'cores': psutil.cpu_count(logical=False),&#13;&#10;        'threads': psutil.cpu_count(logical=True),&#13;&#10;        'ram_gb': round(psutil.virtual_memory().total / 1e9, 2),&#13;&#10;        'os': platform.system(),&#13;&#10;        'gpu': None&#13;&#10;    }&#13;&#10;    try:&#13;&#10;        result = subprocess.run(&#13;&#10;            [&#13;&#10;                'nvidia-smi',&#13;&#10;                '--query-gpu=name,memory.total',&#13;&#10;                '--format=csv,noheader'&#13;&#10;            ],&#13;&#10;            capture_output=True,&#13;&#10;            text=True,&#13;&#10;            check=True&#13;&#10;        )&#13;&#10;        gpus = []&#13;&#10;        for line in result.stdout.strip().split('\n'):&#13;&#10;            name, mem = line.split(',')&#13;&#10;            gpus.append({&#13;&#10;                'name': name.strip(),&#13;&#10;                'memory_gb': float(mem.strip().split()[0]) / 1024&#13;&#10;            })&#13;&#10;        profile['gpu'] = gpus&#13;&#10;    except subprocess.SubprocessError:&#13;&#10;        profile['gpu'] = []&#13;&#10;    return profile" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Client/reputation.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Client/reputation.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Module for managing user reputation.&#10;&quot;&quot;&quot;&#10;&#10;class ReputationManager:&#10;    &quot;&quot;&quot;Handles reputation value and updates.&quot;&quot;&quot;&#10;    def __init__(self, initial_value: int = 0):&#10;        self.reputation = initial_value&#10;&#10;    def update_reputation(self, change: int) -&gt; int:&#10;        &quot;&quot;&quot;Update reputation by change and return new value.&quot;&quot;&quot;&#10;        self.reputation += change&#10;        return self.reputation&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Demo script for ReputationManager.&quot;&quot;&quot;&#10;    manager = ReputationManager()&#10;    print(&quot;Initial reputation:&quot;, manager.reputation)&#10;    changes = [10, -20, 15, -5, 25]&#10;    for change in changes:&#10;        new_reputation = manager.update_reputation(change)&#10;        print(f&quot;Applied change {change}: Reputation is now {new_reputation}&quot;)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Manages node reputation scores based on performance and reliability.&#10;&quot;&quot;&quot;&#10;import json&#10;&#10;&#10;class ReputationManager:&#10;    &quot;&quot;&quot;Handles loading, updating, and saving node reputation scores.&quot;&quot;&quot;&#10;&#10;    def __init__(self, filepath: str = 'reputation.json'):&#10;        self.filepath = filepath&#10;        self.scores = self._load()&#10;&#10;    def _load(self) -&gt; dict:&#10;        &quot;&quot;&quot;Load reputation scores from file.&quot;&quot;&quot;&#10;        try:&#10;            with open(self.filepath, 'r') as f:&#10;                return json.load(f)&#10;        except FileNotFoundError:&#10;            return {}&#10;&#10;    def _save(self):&#10;        &quot;&quot;&quot;Save current reputation scores to file.&quot;&quot;&quot;&#10;        with open(self.filepath, 'w') as f:&#10;            json.dump(self.scores, f, indent=2)&#10;&#10;    def update_score(self, node_id: str, change: float):&#10;        &quot;&quot;&quot;Update a node's score and save.&quot;&quot;&quot;&#10;        current_score = self.scores.get(node_id, 1.0)&#10;        self.scores[node_id] = max(0, current_score + change)&#10;        self._save()&#10;&#10;    def get_score(self, node_id: str) -&gt; float:&#10;        &quot;&quot;&quot;Get a node's current score.&quot;&quot;&quot;&#10;        return self.scores.get(node_id, 1.0)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/Descriptor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/Descriptor.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Module defining descriptors for infrastructure components.&#10;&quot;&quot;&quot;&#10;from dataclasses import dataclass&#10;&#10;@dataclass&#10;class RateLimitDescriptor:&#10;    &quot;&quot;&quot;Descriptor for rate limiter configuration.&quot;&quot;&quot;&#10;    max_calls: int&#10;    period_seconds: float&#10;&#10;__all__ = [&quot;RateLimitDescriptor&quot;]&#10;&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Module defining descriptors for infrastructure components.&#10;&quot;&quot;&quot;&#10;from dataclasses import dataclass&#10;&#10;&#10;@dataclass&#10;class RateLimitDescriptor:&#10;    &quot;&quot;&quot;Descriptor for rate limiter configuration.&quot;&quot;&quot;&#10;    max_calls: int&#10;    period_seconds: float&#10;&#10;&#10;__all__ = [&quot;RateLimitDescriptor&quot;]" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/__init__.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/__init__.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Infrastructure package for NEXAPod.&#10;&quot;&quot;&quot;&#10;from .api import app, scheduler, db&#10;&#10;__all__ = [&#10;    &quot;app&quot;,&#10;    &quot;scheduler&quot;,&#10;    &quot;db&quot;&#10;]&#10;&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#13;&#10;Infrastructure package for NEXAPod.&#13;&#10;&quot;&quot;&quot;&#13;&#10;from .api import app, scheduler, db&#13;&#10;&#13;&#10;__all__ = [&#13;&#10;    &quot;app&quot;,&#13;&#10;    &quot;scheduler&quot;,&#13;&#10;    &quot;db&quot;&#13;&#10;]" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/api.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/api.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;REST API for NEXAPod coordinator.&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;from flask import Flask, request, jsonify&#10;from .node import Node&#10;from .tier import Tier&#10;from .scheduler import Scheduler&#10;from .database import Database&#10;&#10;app = Flask(__name__)&#10;scheduler = Scheduler()&#10;db = Database()&#10;&#10;@app.route('/register', methods=['POST'])&#10;def register():&#10;    &quot;&quot;&quot;Register a new node with its profile and tier.&quot;&quot;&quot;&#10;    data = request.get_json()&#10;    node = Node(data.get('id'), Tier(data.get('tier')))&#10;    db.store_node({&#10;        &quot;id&quot;: node.id,&#10;        &quot;tier&quot;: node.tier.value,&#10;        &quot;profile&quot;: node.profile&#10;    })&#10;    return jsonify({&quot;status&quot;: &quot;registered&quot;, &quot;node&quot;: node.id})&#10;&#10;@app.route('/submit-job', methods=['POST'])&#10;def submit_job():&#10;    &quot;&quot;&quot;Accept a job submission and enqueue it for scheduling.&quot;&quot;&quot;&#10;    job = request.get_json()&#10;    scheduler.submit_job(job)&#10;    return jsonify({&quot;status&quot;: &quot;job submitted&quot;, &quot;job_id&quot;: job.get('id')})&#10;&#10;@app.route('/status', methods=['GET'])&#10;def status():&#10;    &quot;&quot;&quot;Return current nodes and jobs stored in the database.&quot;&quot;&quot;&#10;    return jsonify({&#10;        &quot;nodes&quot;: db.get_nodes(),&#10;        &quot;jobs&quot;: db.get_jobs()&#10;    })&#10;&#10;if __name__ == '__main__':&#10;    host = os.getenv('HOST', '0.0.0.0')&#10;    port = int(os.getenv('PORT', 8000))&#10;    app.run(host=host, port=port)&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;REST API for NEXAPod coordinator.&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;from flask import Flask, request, jsonify&#10;from .node import Node&#10;from .tier import Tier&#10;from .scheduler import Scheduler&#10;from .database import Database&#10;&#10;app = Flask(__name__)&#10;scheduler = Scheduler()&#10;db = Database()&#10;&#10;&#10;@app.route('/register', methods=['POST'])&#10;def register():&#10;    &quot;&quot;&quot;Register a new node with its profile and tier.&quot;&quot;&quot;&#10;    data = request.get_json()&#10;    node = Node(data.get('id'), Tier(data.get('tier')))&#10;    db.store_node({&#10;        &quot;id&quot;: node.id,&#10;        &quot;tier&quot;: node.tier.value,&#10;        &quot;profile&quot;: node.profile&#10;    })&#10;    return jsonify({&quot;status&quot;: &quot;registered&quot;, &quot;node&quot;: node.id})&#10;&#10;&#10;@app.route('/submit-job', methods=['POST'])&#10;def submit_job():&#10;    &quot;&quot;&quot;Accept a job submission and enqueue it for scheduling.&quot;&quot;&quot;&#10;    job = request.get_json()&#10;    scheduler.submit_job(job)&#10;    return jsonify({&quot;status&quot;: &quot;job submitted&quot;, &quot;job_id&quot;: job.get('id')})&#10;&#10;&#10;@app.route('/status', methods=['GET'])&#10;def status():&#10;    &quot;&quot;&quot;Return current nodes and jobs stored in the database.&quot;&quot;&quot;&#10;    return jsonify({&#10;        &quot;nodes&quot;: db.get_nodes(),&#10;        &quot;jobs&quot;: db.get_jobs()&#10;    })&#10;&#10;&#10;if __name__ == '__main__':&#10;    host = os.getenv('HOST', '0.0.0.0')&#10;    port = int(os.getenv('PORT', 8000))&#10;    app.run(host=host, port=port)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/database.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/database.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Database access layer for NEXAPod coordinator.&#10;&quot;&quot;&quot;&#10;import sqlite3&#10;&#10;&#10;class Database:&#10;    &quot;&quot;&quot;Handles persistence of nodes, jobs, and logs.&quot;&quot;&quot;&#10;    def __init__(self, path: str = 'nexapod.db'):&#10;        self.conn = sqlite3.connect(path, check_same_thread=False)&#10;        self.create_tables()&#10;&#10;    def create_tables(self):&#10;        &quot;&quot;&quot;Create tables for nodes, jobs, and logs if they do not exist.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&#10;            '''CREATE TABLE IF NOT EXISTS nodes (&#10;               id TEXT PRIMARY KEY,&#10;               tier TEXT,&#10;               profile TEXT)'''&#10;        )&#10;        cursor.execute(&#10;            '''CREATE TABLE IF NOT EXISTS jobs (&#10;               id TEXT PRIMARY KEY,&#10;               data TEXT,&#10;               result TEXT)'''&#10;        )&#10;        cursor.execute(&#10;            '''CREATE TABLE IF NOT EXISTS logs (&#10;               id INTEGER PRIMARY KEY AUTOINCREMENT,&#10;               job_id TEXT,&#10;               log TEXT)'''&#10;        )&#10;        self.conn.commit()&#10;&#10;    def store_node(self, node: dict):&#10;        &quot;&quot;&quot;Insert or update a node record.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&#10;            'INSERT OR REPLACE INTO nodes VALUES (?,?,?)',&#10;            (node['id'], node['tier'], str(node['profile']))&#10;        )&#10;        self.conn.commit()&#10;&#10;    def store_job(self, job: dict, result: dict):&#10;        &quot;&quot;&quot;Insert or update a job record with its result.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&#10;            'INSERT OR REPLACE INTO jobs VALUES (?,?,?)',&#10;            (job['id'], str(job), str(result))&#10;        )&#10;        self.conn.commit()&#10;&#10;    def get_nodes(self) -&gt; list:&#10;        &quot;&quot;&quot;Retrieve all stored nodes.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute('SELECT * FROM nodes')&#10;        return cursor.fetchall()&#10;&#10;    def get_jobs(self) -&gt; list:&#10;        &quot;&quot;&quot;Retrieve all stored jobs.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute('SELECT * FROM jobs')&#10;        return cursor.fetchall()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Database access layer for NEXAPod coordinator.&#10;&quot;&quot;&quot;&#10;&#10;import sqlite3&#10;&#10;&#10;class Database:&#10;    &quot;&quot;&quot;Handles persistence of nodes, jobs, and logs.&quot;&quot;&quot;&#10;    def __init__(self, path: str = &quot;nexapod.db&quot;):&#10;        self.conn = sqlite3.connect(path, check_same_thread=False)&#10;        self.create_tables()&#10;&#10;    def create_tables(self):&#10;        &quot;&quot;&quot;Create tables for nodes, jobs, and logs if they do not exist.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS nodes (&#10;               id TEXT PRIMARY KEY,&#10;               tier TEXT,&#10;               profile TEXT)&quot;&quot;&quot;&#10;        )&#10;        cursor.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS jobs (&#10;               id TEXT PRIMARY KEY,&#10;               data TEXT,&#10;               result TEXT)&quot;&quot;&quot;&#10;        )&#10;        cursor.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS logs (&#10;               id INTEGER PRIMARY KEY AUTOINCREMENT,&#10;               job_id TEXT,&#10;               log TEXT)&quot;&quot;&quot;&#10;        )&#10;        self.conn.commit()&#10;&#10;    def store_node(self, node: dict):&#10;        &quot;&quot;&quot;Insert or update a node record.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&#10;            &quot;INSERT OR REPLACE INTO nodes VALUES (?,?,?)&quot;,&#10;            (node[&quot;id&quot;], node[&quot;tier&quot;], str(node[&quot;profile&quot;]))&#10;        )&#10;        self.conn.commit()&#10;&#10;    def store_job(self, job: dict, result: dict):&#10;        &quot;&quot;&quot;Insert or update a job record with its result.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&#10;            &quot;INSERT OR REPLACE INTO jobs VALUES (?,?,?)&quot;,&#10;            (job[&quot;id&quot;], str(job), str(result))&#10;        )&#10;        self.conn.commit()&#10;&#10;    def get_nodes(self) -&gt; list:&#10;        &quot;&quot;&quot;Retrieve all stored nodes.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&quot;SELECT * FROM nodes&quot;)&#10;        return cursor.fetchall()&#10;&#10;    def get_jobs(self) -&gt; list:&#10;        &quot;&quot;&quot;Retrieve all stored jobs.&quot;&quot;&quot;&#10;        cursor = self.conn.cursor()&#10;        cursor.execute(&quot;SELECT * FROM jobs&quot;)&#10;        return cursor.fetchall()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/replication.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/replication.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Module for job replication strategies.&#10;&quot;&quot;&quot;&#10;&#10;import logging&#10;from nexapod.descriptor import JobDescriptor&#10;&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;class Replicator:&#10;    &quot;&quot;&quot;Performs replication logic for computed jobs.&quot;&quot;&quot;&#10;    def __init__(self):&#10;        pass&#10;&#10;    def replicate(self, job: JobDescriptor) -&gt; bool:&#10;        &quot;&quot;&quot;Replicate computation based on job descriptor.&quot;&quot;&quot;&#10;        logger.info(&quot;Starting replication for job: %s&quot;, job.id)&#10;        if getattr(job, &quot;needs_replication&quot;, False):&#10;            logger.info(&quot;Replication required for job: %s&quot;, job.id)&#10;            # ...existing code...&#10;            return True&#10;        logger.info(&quot;No replication required for job: %s&quot;, job.id)&#10;        return False&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Module for job replication strategies.&#10;&quot;&quot;&quot;&#10;&#10;import logging&#10;from nexapod.descriptor import JobDescriptor&#10;&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;class Replicator:&#10;    &quot;&quot;&quot;Performs replication logic for computed jobs.&quot;&quot;&quot;&#10;    def __init__(self):&#10;        pass&#10;&#10;    def replicate(self, job: JobDescriptor) -&gt; bool:&#10;        &quot;&quot;&quot;Replicate computation based on job descriptor.&quot;&quot;&quot;&#10;        logger.info(&quot;Starting replication for job: %s&quot;, job.id)&#10;        if getattr(job, &quot;needs_replication&quot;, False):&#10;            logger.info(&quot;Replication required for job: %s&quot;, job.id)&#10;            # ...existing code...&#10;            return True&#10;        logger.info(&quot;No replication required for job: %s&quot;, job.id)&#10;        return False&#10;&#10;&#10;def replicate_data():&#10;    # ...existing code...&#10;    pass" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/runner.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/runner.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Container runner using Docker to execute jobs in isolation.&#10;&quot;&quot;&quot;&#10;import docker&#10;from nexapod.descriptor import JobDescriptor&#10;&#10;class ContainerRunner:&#10;    &quot;&quot;&quot;Executes job containers based on job descriptors.&quot;&quot;&quot;&#10;    def __init__(self):&#10;        self.client = docker.from_env()&#10;&#10;    def run(self, desc: JobDescriptor) -&gt; dict:&#10;        &quot;&quot;&quot;Run the container and return execution status and logs.&quot;&quot;&quot;&#10;        volumes = {&#10;            host_path: {'bind': container_path, 'mode': 'rw'}&#10;            for container_path, host_path in desc.outputs.items()&#10;        }&#10;        container = self.client.containers.run(&#10;            desc.image,&#10;            detach=True,&#10;            read_only=True,&#10;            cap_drop=[&quot;ALL&quot;],&#10;            security_opt=[&quot;no-new-privileges&quot;],&#10;            volumes=volumes&#10;        )&#10;        result = container.wait()&#10;        logs = container.logs().decode()&#10;        return {&quot;status&quot;: result.get('StatusCode') == 0, &quot;logs&quot;: logs}&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#13;&#10;Container runner using Docker to execute jobs in isolation.&#13;&#10;&quot;&quot;&quot;&#13;&#10;import docker&#13;&#10;from nexapod.descriptor import JobDescriptor&#13;&#10;&#13;&#10;&#13;&#10;class ContainerRunner:&#13;&#10;    &quot;&quot;&quot;Executes job containers based on job descriptors.&quot;&quot;&quot;&#13;&#10;    def __init__(self):&#13;&#10;        self.client = docker.from_env()&#13;&#10;&#13;&#10;    def run(self, desc: JobDescriptor) -&gt; dict:&#13;&#10;        &quot;&quot;&quot;Run the container and return execution status and logs.&quot;&quot;&quot;&#13;&#10;        volumes = {&#13;&#10;            host_path: {'bind': container_path, 'mode': 'rw'}&#13;&#10;            for container_path, host_path in desc.outputs.items()&#13;&#10;        }&#13;&#10;        container = self.client.containers.run(&#13;&#10;            desc.image,&#13;&#10;            detach=True,&#13;&#10;            read_only=True,&#13;&#10;            cap_drop=[&quot;ALL&quot;],&#13;&#10;            security_opt=[&quot;no-new-privileges&quot;],&#13;&#10;            volumes=volumes&#13;&#10;        )&#13;&#10;        result = container.wait()&#13;&#10;        logs = container.logs().decode()&#13;&#10;        return {&quot;status&quot;: result.get('StatusCode') == 0, &quot;logs&quot;: logs}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/scheduler.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/scheduler.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Scheduler module for matching and executing jobs on nodes.&#10;&quot;&quot;&quot;&#10;import logging&#10;import threading&#10;import queue&#10;import time&#10;import hashlib&#10;import ast&#10;from .database import Database&#10;from .validator import validate_log, generate_signature&#10;&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;job_queue = queue.Queue()&#10;&#10;class Scheduler:&#10;    &quot;&quot;&quot;Responsible for job scheduling and execution across nodes.&quot;&quot;&quot;&#10;    def __init__(self):&#10;        self.db = Database()&#10;        self.node_busy = {}&#10;&#10;    @staticmethod&#10;    def submit_job(job: dict):&#10;        &quot;&quot;&quot;Add a job to the scheduling queue.&quot;&quot;&quot;&#10;        job_queue.put(job)&#10;        logger.info(&quot;Job %s submitted to the queue.&quot;, job['id'])&#10;&#10;    def match_and_schedule(self):&#10;        &quot;&quot;&quot;Continuously match jobs to available nodes and schedule execution.&quot;&quot;&quot;&#10;        while True:&#10;            job = job_queue.get()&#10;            node1, node2 = self._find_two_nodes_for_job()&#10;            if not node1 or not node2:&#10;                logger.warning(&quot;Insufficient nodes for job %s.&quot;, job['id'])&#10;                job_queue.task_done()&#10;                continue&#10;&#10;            result1 = self._execute_job(job, node1)&#10;            result2 = self._execute_job(job, node2)&#10;&#10;            if validate_log(result1) and validate_log(result2):&#10;                if result1['hash'] == result2['hash']:&#10;                    self.db.store_job(job, result1)&#10;                else:&#10;                    logger.error(&quot;Hash mismatch for job %s.&quot;, job['id'])&#10;            else:&#10;                logger.error(&quot;Validation failed for job %s.&quot;, job['id'])&#10;            job_queue.task_done()&#10;&#10;    def _find_two_nodes_for_job(self) -&gt; tuple:&#10;        &quot;&quot;&quot;Select two available and verified nodes for a given job.&quot;&quot;&quot;&#10;        records = self.db.get_nodes()&#10;        candidates = [&#10;            rec[0]&#10;            for rec in records&#10;            if self._verify_node(rec) and self._is_node_available(rec[0])&#10;        ]&#10;        if len(candidates) &lt; 2:&#10;            return None, None&#10;        return candidates[0], candidates[1]&#10;&#10;    def _verify_node(self, node_record: tuple) -&gt; bool:&#10;        &quot;&quot;&quot;Verify node profile integrity.&quot;&quot;&quot;&#10;        try:&#10;            profile = ast.literal_eval(node_record[2])&#10;            return isinstance(profile, dict) and 'os' in profile&#10;        except Exception:&#10;            return False&#10;&#10;    def _is_node_available(self, node_id: str) -&gt; bool:&#10;        &quot;&quot;&quot;Check if the node is currently free.&quot;&quot;&quot;&#10;        return not self.node_busy.get(node_id, False)&#10;&#10;    def _execute_job(self, job: dict, node_id: str) -&gt; dict:&#10;        &quot;&quot;&quot;Execute a job on a node and return execution metadata.&quot;&quot;&quot;&#10;        self.node_busy[node_id] = True&#10;        try:&#10;            time.sleep(1)&#10;            combined = f&quot;{job['id']}_{node_id}&quot;&#10;            hash_result = hashlib.sha256(combined.encode()).hexdigest()&#10;            signature = generate_signature(str(job['id']).encode())&#10;            return {&quot;id&quot;: job['id'], &quot;hash&quot;: hash_result, &quot;signature&quot;: signature}&#10;        finally:&#10;            self.node_busy[node_id] = False&#10;&#10;def start_scheduler() -&gt; threading.Thread:&#10;    &quot;&quot;&quot;Initialize and start the scheduler in a background thread.&quot;&quot;&quot;&#10;    scheduler = Scheduler()&#10;    thread = threading.Thread(target=scheduler.match_and_schedule, daemon=True)&#10;    thread.start()&#10;    return thread&#10;&#10;def main():&#10;    &quot;&quot;&quot;Entry point to start the scheduler module.&quot;&quot;&quot;&#10;    thread = start_scheduler()&#10;    thread.join()&#10;&#10;if __name__ == '__main__':&#10;    main()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#13;&#10;Scheduler module for matching and executing jobs on nodes.&#13;&#10;&quot;&quot;&quot;&#13;&#10;import logging&#13;&#10;import threading&#13;&#10;import queue&#13;&#10;import time&#13;&#10;import hashlib&#13;&#10;import ast&#13;&#10;from .database import Database&#13;&#10;from .validator import validate_log, generate_signature&#13;&#10;&#13;&#10;logging.basicConfig(level=logging.INFO)&#13;&#10;logger = logging.getLogger(__name__)&#13;&#10;&#13;&#10;job_queue = queue.Queue()&#13;&#10;&#13;&#10;&#13;&#10;class Scheduler:&#13;&#10;    &quot;&quot;&quot;Responsible for job scheduling and execution across nodes.&quot;&quot;&quot;&#13;&#10;    def __init__(self):&#13;&#10;        self.db = Database()&#13;&#10;        self.node_busy = {}&#13;&#10;&#13;&#10;    @staticmethod&#13;&#10;    def submit_job(job: dict):&#13;&#10;        &quot;&quot;&quot;Add a job to the scheduling queue.&quot;&quot;&quot;&#13;&#10;        job_queue.put(job)&#13;&#10;        logger.info(&quot;Job %s submitted to the queue.&quot;, job['id'])&#13;&#10;&#13;&#10;    def match_and_schedule(self):&#13;&#10;        &quot;&quot;&quot;Continuously match jobs to available nodes and schedule execution.&quot;&quot;&quot;&#13;&#10;        while True:&#13;&#10;            job = job_queue.get()&#13;&#10;            node1, node2 = self._find_two_nodes_for_job()&#13;&#10;            if not node1 or not node2:&#13;&#10;                logger.warning(&quot;Insufficient nodes for job %s.&quot;, job['id'])&#13;&#10;                job_queue.task_done()&#13;&#10;                continue&#13;&#10;&#13;&#10;            result1 = self._execute_job(job, node1)&#13;&#10;            result2 = self._execute_job(job, node2)&#13;&#10;&#13;&#10;            if validate_log(result1) and validate_log(result2):&#13;&#10;                if result1['hash'] == result2['hash']:&#13;&#10;                    self.db.store_job(job, result1)&#13;&#10;                else:&#13;&#10;                    logger.error(&quot;Hash mismatch for job %s.&quot;, job['id'])&#13;&#10;            else:&#13;&#10;                logger.error(&quot;Validation failed for job %s.&quot;, job['id'])&#13;&#10;            job_queue.task_done()&#13;&#10;&#13;&#10;    def _find_two_nodes_for_job(self) -&gt; tuple:&#13;&#10;        &quot;&quot;&quot;Select two available and verified nodes for a given job.&quot;&quot;&quot;&#13;&#10;        records = self.db.get_nodes()&#13;&#10;        candidates = [&#13;&#10;            rec[0]&#13;&#10;            for rec in records&#13;&#10;            if self._verify_node(rec) and self._is_node_available(rec[0])&#13;&#10;        ]&#13;&#10;        if len(candidates) &lt; 2:&#13;&#10;            return None, None&#13;&#10;        return candidates[0], candidates[1]&#13;&#10;&#13;&#10;    def _verify_node(self, node_record: tuple) -&gt; bool:&#13;&#10;        &quot;&quot;&quot;Verify node profile integrity.&quot;&quot;&quot;&#13;&#10;        try:&#13;&#10;            profile = ast.literal_eval(node_record[2])&#13;&#10;            return isinstance(profile, dict) and 'os' in profile&#13;&#10;        except Exception:&#13;&#10;            return False&#13;&#10;&#13;&#10;    def _is_node_available(self, node_id: str) -&gt; bool:&#13;&#10;        &quot;&quot;&quot;Check if the node is currently free.&quot;&quot;&quot;&#13;&#10;        return not self.node_busy.get(node_id, False)&#13;&#10;&#13;&#10;    def _execute_job(self, job: dict, node_id: str) -&gt; dict:&#13;&#10;        &quot;&quot;&quot;Execute a job on a node and return execution metadata.&quot;&quot;&quot;&#13;&#10;        self.node_busy[node_id] = True&#13;&#10;        try:&#13;&#10;            time.sleep(1)&#13;&#10;            combined = f&quot;{job['id']}_{node_id}&quot;&#13;&#10;            hash_result = hashlib.sha256(combined.encode()).hexdigest()&#13;&#10;            signature = generate_signature(str(job['id']).encode())&#13;&#10;            return {&quot;id&quot;: job['id'], &quot;hash&quot;: hash_result,&#13;&#10;                    &quot;signature&quot;: signature}&#13;&#10;        finally:&#13;&#10;            self.node_busy[node_id] = False&#13;&#10;&#13;&#10;&#13;&#10;def start_scheduler() -&gt; threading.Thread:&#13;&#10;    &quot;&quot;&quot;Initialize and start the scheduler in a background thread.&quot;&quot;&quot;&#13;&#10;    scheduler = Scheduler()&#13;&#10;    thread = threading.Thread(target=scheduler.match_and_schedule,&#13;&#10;                              daemon=True)&#13;&#10;    thread.start()&#13;&#10;    return thread&#13;&#10;&#13;&#10;&#13;&#10;def main():&#13;&#10;    &quot;&quot;&quot;Entry point to start the scheduler module.&quot;&quot;&quot;&#13;&#10;    thread = start_scheduler()&#13;&#10;    thread.join()&#13;&#10;&#13;&#10;&#13;&#10;if __name__ == '__main__':&#13;&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Infrastruture/validator.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Infrastruture/validator.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Module for HMAC-based signature generation and log validation.&#10;&quot;&quot;&quot;&#10;&#10;import hashlib&#10;import hmac&#10;&#10;SECRET_KEY = b'supersecret'&#10;&#10;def generate_signature(message: bytes) -&gt; str:&#10;    &quot;&quot;&quot;Generate HMAC-SHA256 signature for a message.&quot;&quot;&quot;&#10;    return hmac.new(SECRET_KEY, message, hashlib.sha256).hexdigest()&#10;&#10;def validate_log(log: dict) -&gt; bool:&#10;    &quot;&quot;&quot;Validate the signature of a log entry.&quot;&quot;&quot;&#10;    expected = generate_signature(str(log.get('id', '')).encode())&#10;    return log.get('signature') == expected&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Module for HMAC-based signature generation and log validation.&#10;&quot;&quot;&quot;&#10;&#10;import hashlib&#10;import hmac&#10;&#10;SECRET_KEY = b'supersecret'&#10;&#10;&#10;def generate_signature(message: bytes) -&gt; str:&#10;    &quot;&quot;&quot;Generate HMAC-SHA256 signature for a message.&quot;&quot;&quot;&#10;    return hmac.new(SECRET_KEY, message, hashlib.sha256).hexdigest()&#10;&#10;&#10;def validate_log(log: dict) -&gt; bool:&#10;    &quot;&quot;&quot;Validate the signature of a log entry.&quot;&quot;&quot;&#10;    expected = generate_signature(str(log.get('id', '')).encode())&#10;    return log.get('signature') == expected" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Protocol/incentives/bounties.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Protocol/incentives/bounties.py" />
              <option name="originalContent" value="# Coming soon&#10;&#10;" />
              <option name="updatedContent" value="# Coming soon" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Protocol/incentives/credits.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Protocol/incentives/credits.py" />
              <option name="originalContent" value="# Coming Soon&#10;&#10;" />
              <option name="updatedContent" value="# Coming Soon" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Protocol/protocol.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Protocol/protocol.py" />
              <option name="originalContent" value="import pydantic&#10;&#10;class NodeProfile(pydantic.BaseModel):&#10;    cpu: str&#10;    cores: int&#10;    threads: int&#10;    ram_gb: float&#10;    os: str&#10;    gpu: list&#10;&#10;class JobRequest(pydantic.BaseModel):&#10;    node_id: str&#10;&#10;class JobDescriptor(pydantic.BaseModel):&#10;    schema_version: str&#10;    job_id: str&#10;    type: str&#10;    input_files: list&#10;    docker_image: str&#10;    estimated_flops: float&#10;    tier: int&#10;    requirements: dict&#10;    input_uri: str&#10;    tolerance: float&#10;    credit_rate: float&#10;&#10;class JobResult(pydantic.BaseModel):&#10;    job_id: str&#10;    node_id: str&#10;    output: str&#10;    status: str&#10;    timestamp: int&#10;    sha256: str&#10;    signature: str&#10;&#10;" />
              <option name="updatedContent" value="import pydantic&#13;&#10;&#13;&#10;&#13;&#10;class NodeProfile(pydantic.BaseModel):&#13;&#10;    cpu: str&#13;&#10;    cores: int&#13;&#10;    threads: int&#13;&#10;    ram_gb: float&#13;&#10;    os: str&#13;&#10;    gpu: list&#13;&#10;&#13;&#10;&#13;&#10;class JobRequest(pydantic.BaseModel):&#13;&#10;    node_id: str&#13;&#10;&#13;&#10;&#13;&#10;class JobDescriptor(pydantic.BaseModel):&#13;&#10;    schema_version: str&#13;&#10;    job_id: str&#13;&#10;    type: str&#13;&#10;    input_files: list&#13;&#10;    docker_image: str&#13;&#10;    estimated_flops: float&#13;&#10;    tier: int&#13;&#10;    requirements: dict&#13;&#10;    input_uri: str&#13;&#10;    tolerance: float&#13;&#10;    credit_rate: float&#13;&#10;&#13;&#10;&#13;&#10;class JobResult(pydantic.BaseModel):&#13;&#10;    job_id: str&#13;&#10;    node_id: str&#13;&#10;    output: str&#13;&#10;    status: str&#13;&#10;    timestamp: int&#13;&#10;    sha256: str&#13;&#10;    signature: str" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Protocol/security/security.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Protocol/security/security.py" />
              <option name="originalContent" value="from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey&#10;from cryptography.hazmat.primitives import serialization, hashes&#10;&#10;def generate_node_keypair():&#10;    sk = Ed25519PrivateKey.generate()&#10;    pk = sk.public_key()&#10;    # ...serialize &amp; store in DB...&#10;    return sk, pk&#10;&#10;def sign_log(sk, message: bytes) -&gt; bytes:&#10;    return sk.sign(message)&#10;&#10;" />
              <option name="updatedContent" value="from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PrivateKey&#10;&#10;&#10;def generate_node_keypair():&#10;    sk = Ed25519PrivateKey.generate()&#10;    pk = sk.public_key()&#10;    # ...serialize &amp; store in DB...&#10;    return sk, pk&#10;&#10;&#10;def sign_log(sk, message: bytes) -&gt; bytes:&#10;    return sk.sign(message)" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Runner/Bio_Runner.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Runner/Bio_Runner.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Runner module for protein secondary structure prediction.&#10;&quot;&quot;&quot;&#10;import os&#10;import argparse&#10;import logging&#10;import torch&#10;from Bio import SeqIO&#10;from safetensors.torch import load_file&#10;from comms import CoordinatorClient&#10;from Infrastruture.database import Database&#10;&#10;&#10;logging.basicConfig(level=logging.INFO)&#10;logger = logging.getLogger(__name__)&#10;&#10;&#10;def load_model(model_path: str) -&gt; torch.nn.Module:&#10;    &quot;&quot;&quot;Load and return the protein secondary structure model.&quot;&quot;&quot;&#10;    class ProteinSecStructNet(torch.nn.Module):&#10;        def __init__(self):&#10;            super().__init__()&#10;            self.cnn = torch.nn.Conv1d(21, 128, kernel_size=3, padding=1)&#10;            self.bilstm = torch.nn.LSTM(128, 64, bidirectional=True, batch_first=True)&#10;            self.classifier = torch.nn.Linear(128, 3)&#10;&#10;        def forward(self, x):&#10;            x = self.cnn(x)&#10;            x = x.permute(0, 2, 1)&#10;            x, _ = self.bilstm(x)&#10;            return self.classifier(x)&#10;&#10;    device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;&#10;    state_dict = load_file(os.path.expanduser(model_path))&#10;    model = ProteinSecStructNet()&#10;    model.load_state_dict(state_dict)&#10;    model.to(device)&#10;    model.eval()&#10;    return model&#10;&#10;&#10;AA_VOCAB = &quot;ACDEFGHIKLMNPQRSTVWY&quot;&#10;AA_TO_IDX = {aa: i for i, aa in enumerate(AA_VOCAB)}&#10;&#10;&#10;def one_hot_encode(seq: str) -&gt; torch.Tensor:&#10;    &quot;&quot;&quot;One-hot encode an amino acid sequence.&quot;&quot;&quot;&#10;    arr = torch.zeros(len(seq), len(AA_VOCAB))&#10;    for i, aa in enumerate(seq):&#10;        idx = AA_TO_IDX.get(aa)&#10;        if idx is not None:&#10;            arr[i, idx] = 1.0&#10;    return arr&#10;&#10;&#10;def predict_secstruct(model: torch.nn.Module, seq: str) -&gt; str:&#10;    &quot;&quot;&quot;Predict secondary structure for a single sequence.&quot;&quot;&quot;&#10;    device = next(model.parameters()).device&#10;    x = one_hot_encode(seq).unsqueeze(0).permute(0, 2, 1).to(device)&#10;    with torch.no_grad():&#10;        out = model(x)&#10;        pred = torch.argmax(out, dim=-1).squeeze(0).cpu().tolist()&#10;    idx_to_ss = {0: &quot;H&quot;, 1: &quot;E&quot;, 2: &quot;C&quot;}&#10;    return &quot;&quot;.join(idx_to_ss[i] for i in pred)&#10;&#10;&#10;def process_fasta(model: torch.nn.Module, fasta_path: str) -&gt; list:&#10;    &quot;&quot;&quot;Read FASTA file and predict secondary structures.&quot;&quot;&quot;&#10;    results = []&#10;    for rec in SeqIO.parse(fasta_path, &quot;fasta&quot;):&#10;        ss = predict_secstruct(model, str(rec.seq))&#10;        results.append({&#10;            &quot;id&quot;: rec.id,&#10;            &quot;sequence&quot;: str(rec.seq),&#10;            &quot;predicted_secondary_structure&quot;: ss&#10;        })&#10;    return results&#10;&#10;&#10;def save_results_to_db(results: list, db_path: str):&#10;    &quot;&quot;&quot;Persist prediction results to the local database.&quot;&quot;&quot;&#10;    db = Database(db_path)&#10;    for r in results:&#10;        db.store_job({&quot;id&quot;: r[&quot;id&quot;], &quot;type&quot;: &quot;secstruct&quot;}, r)&#10;&#10;&#10;def submit_results(results: list, client: CoordinatorClient):&#10;    &quot;&quot;&quot;Submit prediction results back to the coordinator.&quot;&quot;&quot;&#10;    for r in results:&#10;        client.submit_result(r)&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Entry point for runner: poll for jobs and perform inference.&quot;&quot;&quot;&#10;    parser = argparse.ArgumentParser(description=&quot;Protein SecStruct Runner&quot;)&#10;    parser.add_argument(&quot;--coordinator-url&quot;, required=True)&#10;    parser.add_argument(&quot;--db-path&quot;, default=&quot;nexapod.db&quot;)&#10;    parser.add_argument(&quot;--model-path&quot;, required=True)&#10;    parser.add_argument(&quot;--input-fasta&quot;, required=True)&#10;    args = parser.parse_args()&#10;&#10;    client = CoordinatorClient({&quot;coordinator_url&quot;: args.coordinator_url})&#10;    model = load_model(args.model_path)&#10;&#10;    while True:&#10;        job = client.poll_job()&#10;        if not job:&#10;            continue&#10;        results = process_fasta(model, args.input_fasta)&#10;        save_results_to_db(results, args.db_path)&#10;        submit_results(results, client)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#13;&#10;Runner module for protein secondary structure prediction.&#13;&#10;&quot;&quot;&quot;&#13;&#10;import os&#13;&#10;import argparse&#13;&#10;import logging&#13;&#10;import torch&#13;&#10;from Bio import SeqIO&#13;&#10;from safetensors.torch import load_file&#13;&#10;from comms import CoordinatorClient&#13;&#10;from Infrastruture.database import Database&#13;&#10;&#13;&#10;&#13;&#10;logging.basicConfig(level=logging.INFO)&#13;&#10;logger = logging.getLogger(__name__)&#13;&#10;&#13;&#10;&#13;&#10;def load_model(model_path: str) -&gt; torch.nn.Module:&#13;&#10;    &quot;&quot;&quot;Load and return the protein secondary structure model.&quot;&quot;&quot;&#13;&#10;    class ProteinSecStructNet(torch.nn.Module):&#13;&#10;        def __init__(self):&#13;&#10;            super().__init__()&#13;&#10;            self.cnn = torch.nn.Conv1d(21, 128, kernel_size=3, padding=1)&#13;&#10;            self.bilstm = torch.nn.LSTM(128, 64, bidirectional=True,&#13;&#10;                                        batch_first=True)&#13;&#10;            self.classifier = torch.nn.Linear(128, 3)&#13;&#10;&#13;&#10;        def forward(self, x):&#13;&#10;            x = self.cnn(x)&#13;&#10;            x = x.permute(0, 2, 1)&#13;&#10;            x, _ = self.bilstm(x)&#13;&#10;            return self.classifier(x)&#13;&#10;&#13;&#10;    device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;&#13;&#10;    state_dict = load_file(os.path.expanduser(model_path))&#13;&#10;    model = ProteinSecStructNet()&#13;&#10;    model.load_state_dict(state_dict)&#13;&#10;    model.to(device)&#13;&#10;    model.eval()&#13;&#10;    return model&#13;&#10;&#13;&#10;&#13;&#10;AA_VOCAB = &quot;ACDEFGHIKLMNPQRSTVWY&quot;&#13;&#10;AA_TO_IDX = {aa: i for i, aa in enumerate(AA_VOCAB)}&#13;&#10;&#13;&#10;&#13;&#10;def one_hot_encode(seq: str) -&gt; torch.Tensor:&#13;&#10;    &quot;&quot;&quot;One-hot encode an amino acid sequence.&quot;&quot;&quot;&#13;&#10;    arr = torch.zeros(len(seq), len(AA_VOCAB))&#13;&#10;    for i, aa in enumerate(seq):&#13;&#10;        idx = AA_TO_IDX.get(aa)&#13;&#10;        if idx is not None:&#13;&#10;            arr[i, idx] = 1.0&#13;&#10;    return arr&#13;&#10;&#13;&#10;&#13;&#10;def predict_secstruct(model: torch.nn.Module, seq: str) -&gt; str:&#13;&#10;    &quot;&quot;&quot;Predict secondary structure for a single sequence.&quot;&quot;&quot;&#13;&#10;    device = next(model.parameters()).device&#13;&#10;    x = one_hot_encode(seq).unsqueeze(0).permute(0, 2, 1).to(device)&#13;&#10;    with torch.no_grad():&#13;&#10;        out = model(x)&#13;&#10;        pred = torch.argmax(out, dim=-1).squeeze(0).cpu().tolist()&#13;&#10;    idx_to_ss = {0: &quot;H&quot;, 1: &quot;E&quot;, 2: &quot;C&quot;}&#13;&#10;    return &quot;&quot;.join(idx_to_ss[i] for i in pred)&#13;&#10;&#13;&#10;&#13;&#10;def process_fasta(model: torch.nn.Module, fasta_path: str) -&gt; list:&#13;&#10;    &quot;&quot;&quot;Read FASTA file and predict secondary structures.&quot;&quot;&quot;&#13;&#10;    results = []&#13;&#10;    for rec in SeqIO.parse(fasta_path, &quot;fasta&quot;):&#13;&#10;        ss = predict_secstruct(model, str(rec.seq))&#13;&#10;        results.append({&#13;&#10;            &quot;id&quot;: rec.id,&#13;&#10;            &quot;sequence&quot;: str(rec.seq),&#13;&#10;            &quot;predicted_secondary_structure&quot;: ss&#13;&#10;        })&#13;&#10;    return results&#13;&#10;&#13;&#10;&#13;&#10;def save_results_to_db(results: list, db_path: str):&#13;&#10;    &quot;&quot;&quot;Persist prediction results to the local database.&quot;&quot;&quot;&#13;&#10;    db = Database(db_path)&#13;&#10;    for r in results:&#13;&#10;        db.store_job({&quot;id&quot;: r[&quot;id&quot;], &quot;type&quot;: &quot;secstruct&quot;}, r)&#13;&#10;&#13;&#10;&#13;&#10;def submit_results(results: list, client: CoordinatorClient):&#13;&#10;    &quot;&quot;&quot;Submit prediction results back to the coordinator.&quot;&quot;&quot;&#13;&#10;    for r in results:&#13;&#10;        client.submit_result(r)&#13;&#10;&#13;&#10;&#13;&#10;def main():&#13;&#10;    &quot;&quot;&quot;Entry point for runner: poll for jobs and perform inference.&quot;&quot;&quot;&#13;&#10;    parser = argparse.ArgumentParser(description=&quot;Protein SecStruct Runner&quot;)&#13;&#10;    parser.add_argument(&quot;--coordinator-url&quot;, required=True)&#13;&#10;    parser.add_argument(&quot;--db-path&quot;, default=&quot;nexapod.db&quot;)&#13;&#10;    parser.add_argument(&quot;--model-path&quot;, required=True)&#13;&#10;    parser.add_argument(&quot;--input-fasta&quot;, required=True)&#13;&#10;    args = parser.parse_args()&#13;&#10;&#13;&#10;    client = CoordinatorClient({&quot;coordinator_url&quot;: args.coordinator_url})&#13;&#10;    model = load_model(args.model_path)&#13;&#10;&#13;&#10;    while True:&#13;&#10;        job = client.poll_job()&#13;&#10;        if not job:&#13;&#10;            continue&#13;&#10;        results = process_fasta(model, args.input_fasta)&#13;&#10;        save_results_to_db(results, args.db_path)&#13;&#10;        submit_results(results, client)&#13;&#10;&#13;&#10;&#13;&#10;if __name__ == &quot;__main__&quot;:&#13;&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Server/app.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Server/app.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;REST API for NEXAPod server coordinator.&#10;&quot;&quot;&quot;&#10;import os&#10;import json&#10;import yaml&#10;import uvicorn&#10;from fastapi import FastAPI, Request, Response, HTTPException&#10;from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PublicKey&#10;from prometheus_client import Counter, generate_latest, CONTENT_TYPE_LATEST&#10;from Server.scheduler import Scheduler&#10;from Server.db import DB&#10;from Server.reputation import Reputation&#10;from Infrastruture.output_validator import load_checker&#10;&#10;&#10;CONFIG_PATH = os.path.join(os.path.dirname(__file__), &quot;config.yaml&quot;)&#10;&#10;&#10;def load_config() -&gt; dict:&#10;    &quot;&quot;&quot;Load and return the server configuration from YAML.&quot;&quot;&quot;&#10;    with open(CONFIG_PATH, &quot;r&quot;) as f:&#10;        return yaml.safe_load(f)&#10;&#10;&#10;def create_app() -&gt; FastAPI:&#10;    &quot;&quot;&quot;Create and configure the FastAPI application.&quot;&quot;&quot;&#10;    config = load_config()&#10;    validator = load_checker(config[&quot;validator_plugin&quot;])&#10;    quorum = config.get(&quot;quorum&quot;, 1)&#10;    db = DB(config)&#10;    scheduler = Scheduler(db, config)&#10;    reputation = Reputation(db, config)&#10;    app = FastAPI()&#10;&#10;    node_register_counter = Counter(&#10;        &quot;nexapod_node_register_total&quot;, &quot;Total number of node registrations&quot;&#10;    )&#10;    job_assigned_counter = Counter(&#10;        &quot;nexapod_job_assigned_total&quot;, &quot;Total number of jobs assigned&quot;&#10;    )&#10;    job_result_success_counter = Counter(&#10;        &quot;nexapod_job_result_success_total&quot;, &quot;Total number of successful job results&quot;&#10;    )&#10;    job_result_failure_counter = Counter(&#10;        &quot;nexapod_job_result_failure_total&quot;, &quot;Total number of failed job results&quot;&#10;    )&#10;    job_submitted_counter = Counter(&#10;        &quot;nexapod_job_submitted_total&quot;,&#10;        &quot;nexapod_job_submitted_total&quot;, &quot;Total number of jobs submitted&quot;&#10;&#10;    @app.post(&quot;/register&quot;)&#10;    async def register_node(request: Request):&#10;        &quot;&quot;&quot;Verify node signature and register profile.&quot;&quot;&quot;&#10;        payload = await request.json()&#10;        signature_hex = payload.pop(&quot;signature&quot;, None)&#10;        public_key_hex = payload.pop(&quot;public_key&quot;, None)&#10;        if not signature_hex or not public_key_hex:&#10;            raise HTTPException(status_code=400, detail=&quot;Missing signature or public_key&quot;)&#10;        message = json.dumps(payload, sort_keys=True).encode()&#10;        public_key = Ed25519PublicKey.from_public_bytes(bytes.fromhex(public_key_hex))&#10;        try:&#10;            public_key.verify(bytes.fromhex(signature_hex), message)&#10;        except Exception:&#10;            raise HTTPException(status_code=400, detail=&quot;Invalid signature&quot;)&#10;        payload[&quot;public_key&quot;] = public_key_hex&#10;        node_id = db.register_node(payload)&#10;        node_register_counter.inc()&#10;        return {&quot;node_id&quot;: node_id}&#10;&#10;    @app.get(&quot;/job&quot;)&#10;    async def get_job(node_id: str):&#10;        &quot;&quot;&quot;Assign and return a pending job for the given node.&quot;&quot;&quot;&#10;        job = scheduler.assign_job(node_id)&#10;        if job:&#10;            job_assigned_counter.inc()&#10;        return job or {}&#10;&#10;    @app.post(&quot;/result&quot;)&#10;    async def submit_result(request: Request):&#10;        &quot;&quot;&quot;Validate and record a job result, finalize when quorum is reached.&quot;&quot;&quot;&#10;        result = await request.json()&#10;        try:&#10;            valid = validator(result)&#10;        except Exception as e:&#10;            job_result_failure_counter.inc()&#10;            raise HTTPException(status_code=400, detail=f&quot;Validation error: {e}&quot;)&#10;        if not valid:&#10;            job_result_failure_counter.inc()&#10;            raise HTTPException(status_code=400, detail=&quot;Result validation failed&quot;)&#10;        db.add_vote(result)&#10;        votes = db.count_votes(result[&quot;job_id&quot;], result[&quot;sha256&quot;])&#10;        if votes &gt;= quorum:&#10;            final = db.get_vote_result(result[&quot;job_id&quot;], result[&quot;sha256&quot;])&#10;            db.finalize_job(final)&#10;            reputation.update_credits(final)&#10;            job_result_success_counter.inc()&#10;            return {&quot;status&quot;: &quot;finalized&quot;, &quot;votes&quot;: votes}&#10;        return {&quot;status&quot;: &quot;vote recorded&quot;, &quot;votes&quot;: votes}&#10;&#10;    @app.post(&quot;/jobs&quot;)&#10;    async def submit_job(request: Request):&#10;        &quot;&quot;&quot;Submit a new job to the scheduling queue.&quot;&quot;&quot;&#10;        job = await request.json()&#10;        db.add_job(job)&#10;        job_submitted_counter.inc()&#10;        return {&quot;status&quot;: &quot;job added&quot;}&#10;&#10;    @app.get(&quot;/metrics&quot;)&#10;    async def metrics():&#10;        &quot;&quot;&quot;Expose Prometheus metrics endpoint.&quot;&quot;&quot;&#10;        data = generate_latest()&#10;        return Response(content=data, media_type=CONTENT_TYPE_LATEST)&#10;&#10;    @app.get(&quot;/health&quot;)&#10;    async def health():&#10;        &quot;&quot;&quot;Health check endpoint.&quot;&quot;&quot;&#10;        return {&quot;status&quot;: &quot;ok&quot;}&#10;&#10;    return app&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Run the Uvicorn server.&quot;&quot;&quot;&#10;    app = create_app()&#10;    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    main()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#13;&#10;REST API for NEXAPod server coordinator.&#13;&#10;&quot;&quot;&quot;&#13;&#10;import os&#13;&#10;import json&#13;&#10;import yaml&#13;&#10;import uvicorn&#13;&#10;from fastapi import FastAPI, Request, Response, HTTPException&#13;&#10;from cryptography.hazmat.primitives.asymmetric.ed25519 import Ed25519PublicKey&#13;&#10;from prometheus_client import Counter, generate_latest, CONTENT_TYPE_LATEST&#13;&#10;from Server.scheduler import Scheduler&#13;&#10;from Server.db import DB&#13;&#10;from Server.reputation import Reputation&#13;&#10;from Infrastruture.output_validator import load_checker&#13;&#10;&#13;&#10;&#13;&#10;CONFIG_PATH = os.path.join(os.path.dirname(__file__), &quot;config.yaml&quot;)&#13;&#10;&#13;&#10;&#13;&#10;def load_config() -&gt; dict:&#13;&#10;    &quot;&quot;&quot;Load and return the server configuration from YAML.&quot;&quot;&quot;&#13;&#10;    with open(CONFIG_PATH, &quot;r&quot;) as f:&#13;&#10;        return yaml.safe_load(f)&#13;&#10;&#13;&#10;&#13;&#10;def create_app() -&gt; FastAPI:&#13;&#10;    &quot;&quot;&quot;Create and configure the FastAPI application.&quot;&quot;&quot;&#13;&#10;    config = load_config()&#13;&#10;    validator = load_checker(config[&quot;validator_plugin&quot;])&#13;&#10;    quorum = config.get(&quot;quorum&quot;, 1)&#13;&#10;    db = DB(config)&#13;&#10;    scheduler = Scheduler(db, config)&#13;&#10;    reputation = Reputation(db, config)&#13;&#10;    app = FastAPI()&#13;&#10;&#13;&#10;    node_register_counter = Counter(&#13;&#10;        &quot;nexapod_node_register_total&quot;, &quot;Total number of node registrations&quot;&#13;&#10;    )&#13;&#10;    job_assigned_counter = Counter(&#13;&#10;        &quot;nexapod_job_assigned_total&quot;, &quot;Total number of jobs assigned&quot;&#13;&#10;    )&#13;&#10;    job_result_success_counter = Counter(&#13;&#10;        &quot;nexapod_job_result_success_total&quot;,&#13;&#10;        &quot;Total number of successful job results&quot;&#13;&#10;    )&#13;&#10;    job_result_failure_counter = Counter(&#13;&#10;        &quot;nexapod_job_result_failure_total&quot;,&#13;&#10;        &quot;Total number of failed job results&quot;&#13;&#10;    )&#13;&#10;    job_submitted_counter = Counter(&#13;&#10;        &quot;nexapod_job_submitted_total&quot;,&#13;&#10;        &quot;Total number of jobs submitted&quot;&#13;&#10;    )&#13;&#10;&#13;&#10;    @app.post(&quot;/register&quot;)&#13;&#10;    async def register_node(request: Request):&#13;&#10;        &quot;&quot;&quot;Verify node signature and register profile.&quot;&quot;&quot;&#13;&#10;        payload = await request.json()&#13;&#10;        signature_hex = payload.pop(&quot;signature&quot;, None)&#13;&#10;        public_key_hex = payload.pop(&quot;public_key&quot;, None)&#13;&#10;        if not signature_hex or not public_key_hex:&#13;&#10;            raise HTTPException(status_code=400, detail=&quot;Missing signature or public_key&quot;)&#13;&#10;        message = json.dumps(payload, sort_keys=True).encode()&#13;&#10;        public_key = Ed25519PublicKey.from_public_bytes(bytes.fromhex(public_key_hex))&#13;&#10;        try:&#13;&#10;            public_key.verify(bytes.fromhex(signature_hex), message)&#13;&#10;        except Exception:&#13;&#10;            raise HTTPException(status_code=400, detail=&quot;Invalid signature&quot;)&#13;&#10;        payload[&quot;public_key&quot;] = public_key_hex&#13;&#10;        node_id = db.register_node(payload)&#13;&#10;        node_register_counter.inc()&#13;&#10;        return {&quot;node_id&quot;: node_id}&#13;&#10;&#13;&#10;    @app.get(&quot;/job&quot;)&#13;&#10;    async def get_job(node_id: str):&#13;&#10;        &quot;&quot;&quot;Assign and return a pending job for the given node.&quot;&quot;&quot;&#13;&#10;        job = scheduler.assign_job(node_id)&#13;&#10;        if job:&#13;&#10;            job_assigned_counter.inc()&#13;&#10;        return job or {}&#13;&#10;&#13;&#10;    @app.post(&quot;/result&quot;)&#13;&#10;    async def submit_result(request: Request):&#13;&#10;        &quot;&quot;&quot;Validate and record a job result, finalize when quorum is reached.&quot;&quot;&quot;&#13;&#10;        result = await request.json()&#13;&#10;        try:&#13;&#10;            valid = validator(result)&#13;&#10;        except Exception as e:&#13;&#10;            job_result_failure_counter.inc()&#13;&#10;            raise HTTPException(status_code=400, detail=f&quot;Validation error: {e}&quot;)&#13;&#10;        if not valid:&#13;&#10;            job_result_failure_counter.inc()&#13;&#10;            raise HTTPException(status_code=400, detail=&quot;Result validation failed&quot;)&#13;&#10;        db.add_vote(result)&#13;&#10;        votes = db.count_votes(result[&quot;job_id&quot;], result[&quot;sha256&quot;])&#13;&#10;        if votes &gt;= quorum:&#13;&#10;            final = db.get_vote_result(result[&quot;job_id&quot;], result[&quot;sha256&quot;])&#13;&#10;            db.finalize_job(final)&#13;&#10;            reputation.update_credits(final)&#13;&#10;            job_result_success_counter.inc()&#13;&#10;            return {&quot;status&quot;: &quot;finalized&quot;, &quot;votes&quot;: votes}&#13;&#10;        return {&quot;status&quot;: &quot;vote recorded&quot;, &quot;votes&quot;: votes}&#13;&#10;&#13;&#10;    @app.post(&quot;/jobs&quot;)&#13;&#10;    async def submit_job(request: Request):&#13;&#10;        &quot;&quot;&quot;Submit a new job to the scheduling queue.&quot;&quot;&quot;&#13;&#10;        job = await request.json()&#13;&#10;        db.add_job(job)&#13;&#10;        job_submitted_counter.inc()&#13;&#10;        return {&quot;status&quot;: &quot;job added&quot;}&#13;&#10;&#13;&#10;    @app.get(&quot;/metrics&quot;)&#13;&#10;    async def metrics():&#13;&#10;        &quot;&quot;&quot;Expose Prometheus metrics endpoint.&quot;&quot;&quot;&#13;&#10;        data = generate_latest()&#13;&#10;        return Response(content=data, media_type=CONTENT_TYPE_LATEST)&#13;&#10;&#13;&#10;    @app.get(&quot;/health&quot;)&#13;&#10;    async def health():&#13;&#10;        &quot;&quot;&quot;Health check endpoint.&quot;&quot;&quot;&#13;&#10;        return {&quot;status&quot;: &quot;ok&quot;}&#13;&#10;&#13;&#10;    return app&#13;&#10;&#13;&#10;&#13;&#10;def main():&#13;&#10;    &quot;&quot;&quot;Run the Uvicorn server.&quot;&quot;&quot;&#13;&#10;    app = create_app()&#13;&#10;    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8000)&#13;&#10;&#13;&#10;&#13;&#10;if __name__ == &quot;__main__&quot;:&#13;&#10;    main()" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/Server/db.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/Server/db.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Database layer for NEXAPod server coordinator.&#10;&quot;&quot;&quot;&#10;import sqlite3&#10;import os&#10;import json&#10;&#10;&#10;class DB:&#10;    &quot;&quot;&quot;Handles persistence of nodes, jobs, results, and votes.&quot;&quot;&quot;&#10;    def __init__(self, config):&#10;        &quot;&quot;&quot;Initialize database connection and ensure tables exist.&quot;&quot;&quot;&#10;        self.db_path = config.get(&quot;db_path&quot;, &quot;nexapod.db&quot;)&#10;        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)&#10;        self._init_tables()&#10;&#10;    def _init_tables(self):&#10;        &quot;&quot;&quot;Create tables for nodes, jobs, results, and votes if they do not exist.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS nodes (&#10;            node_id TEXT PRIMARY KEY,&#10;            profile TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS jobs (&#10;            job_id TEXT PRIMARY KEY,&#10;            job TEXT,&#10;            assigned_node TEXT,&#10;            status TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS results (&#10;            job_id TEXT,&#10;            node_id TEXT,&#10;            result TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS votes (&#10;            job_id TEXT,&#10;            sha256 TEXT,&#10;            node_id TEXT,&#10;            result TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        self.conn.commit()&#10;&#10;    def register_node(self, profile):&#10;        &quot;&quot;&quot;Register a new node profile and return its generated node_id.&quot;&quot;&quot;&#10;        node_id = os.urandom(8).hex()&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO nodes (node_id, profile) VALUES (?, ?)&quot;,&#10;            (node_id, json.dumps(profile))&#10;        )&#10;        self.conn.commit()&#10;        return node_id&#10;&#10;    def add_job(self, job):&#10;        &quot;&quot;&quot;Insert a new job with pending status.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO jobs (job_id, job, assigned_node, status) VALUES (?, ?, ?, ?)&quot;,&#10;            (job[&quot;job_id&quot;], json.dumps(job), None, &quot;pending&quot;)&#10;        )&#10;        self.conn.commit()&#10;&#10;    def assign_job(self, node_id):&#10;        &quot;&quot;&quot;Assign the first pending job to the given node.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT job_id, job FROM jobs WHERE status = ? LIMIT 1&quot;,&#10;            (&quot;pending&quot;,)&#10;        )&#10;        row = c.fetchone()&#10;        if row:&#10;            job_id, job_json = row&#10;            c.execute(&#10;                &quot;UPDATE jobs SET assigned_node = ?, status = ? WHERE job_id = ?&quot;,&#10;                (node_id, &quot;assigned&quot;, job_id)&#10;            )&#10;            self.conn.commit()&#10;            return json.loads(job_json)&#10;        return None&#10;&#10;    def store_result(self, result):&#10;        &quot;&quot;&quot;Store job result and mark the job as completed.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO results (job_id, node_id, result) VALUES (?, ?, ?)&quot;,&#10;            (result[&quot;job_id&quot;], result.get(&quot;node_id&quot;, &quot;&quot;), json.dumps(result))&#10;        )&#10;        c.execute(&#10;            &quot;UPDATE jobs SET status = ? WHERE job_id = ?&quot;,&#10;            (&quot;completed&quot;, result[&quot;job_id&quot;])&#10;        )&#10;        self.conn.commit()&#10;&#10;    def add_vote(self, result):&#10;        &quot;&quot;&quot;Record a vote for a job result from a node.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO votes (job_id, sha256, node_id, result) VALUES (?, ?, ?, ?)&quot;,&#10;            (result[&quot;job_id&quot;], result[&quot;sha256&quot;], result.get(&quot;node_id&quot;, &quot;&quot;), json.dumps(result))&#10;        )&#10;        self.conn.commit()&#10;&#10;    def count_votes(self, job_id, sha256):&#10;        &quot;&quot;&quot;Count distinct votes for a given job_id and hash.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT COUNT(DISTINCT node_id) FROM votes WHERE job_id = ? AND sha256 = ?&quot;,&#10;            (job_id, sha256)&#10;        )&#10;        row = c.fetchone()&#10;        return row[0] if row else 0&#10;&#10;    def get_vote_result(self, job_id, sha256):&#10;        &quot;&quot;&quot;Retrieve the recorded result for a job and hash.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT result FROM votes WHERE job_id = ? AND sha256 = ? LIMIT 1&quot;,&#10;            (job_id, sha256)&#10;        )&#10;        row = c.fetchone()&#10;        return json.loads(row[0]) if row else None&#10;&#10;    def finalize_job(self, result):&#10;        &quot;&quot;&quot;Finalize a job by storing its final result.&quot;&quot;&quot;&#10;        self.store_result(result)&#10;&#10;    def get_node_profile(self, node_id):&#10;        &quot;&quot;&quot;Retrieve stored node profile for a given node_id.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT profile FROM nodes WHERE node_id = ?&quot;,&#10;            (node_id,)&#10;        )&#10;        row = c.fetchone()&#10;        return json.loads(row[0]) if row else None&#10;&#10;    def get_pending_jobs(self):&#10;        &quot;&quot;&quot;Return a list of (job_id, job dict) for all pending jobs.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT job_id, job FROM jobs WHERE status = ?&quot;,&#10;            (&quot;pending&quot;,)&#10;        )&#10;        rows = c.fetchall()&#10;        return [(job_id, json.loads(job_json)) for job_id, job_json in rows]&#10;&#10;    def assign_job_to_node(self, job_id, node_id):&#10;        &quot;&quot;&quot;Mark a job as assigned to a specific node.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;UPDATE jobs SET assigned_node = ?, status = ? WHERE job_id = ?&quot;,&#10;            (node_id, &quot;assigned&quot;, job_id)&#10;        )&#10;        self.conn.commit()&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Database layer for NEXAPod server coordinator.&#10;&quot;&quot;&quot;&#10;import sqlite3&#10;import os&#10;import json&#10;&#10;&#10;class DB:&#10;    &quot;&quot;&quot;Handles persistence of nodes, jobs, results, and votes.&quot;&quot;&quot;&#10;    def __init__(self, config):&#10;        &quot;&quot;&quot;Initialize database connection and ensure tables exist.&quot;&quot;&quot;&#10;        self.db_path = config.get(&quot;db_path&quot;, &quot;nexapod.db&quot;)&#10;        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)&#10;        self._init_tables()&#10;&#10;    def _init_tables(self):&#10;        &quot;&quot;&quot;Create tables for nodes, jobs, results, and votes if they do not exist.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS nodes (&#10;            node_id TEXT PRIMARY KEY,&#10;            profile TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS jobs (&#10;            job_id TEXT PRIMARY KEY,&#10;            job TEXT,&#10;            assigned_node TEXT,&#10;            status TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS results (&#10;            job_id TEXT,&#10;            node_id TEXT,&#10;            result TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        c.execute(&#10;            &quot;&quot;&quot;CREATE TABLE IF NOT EXISTS votes (&#10;            job_id TEXT,&#10;            sha256 TEXT,&#10;            node_id TEXT,&#10;            result TEXT&#10;        )&quot;&quot;&quot;&#10;        )&#10;        self.conn.commit()&#10;&#10;    def register_node(self, profile):&#10;        &quot;&quot;&quot;Register a new node profile and return its generated node_id.&quot;&quot;&quot;&#10;        node_id = os.urandom(8).hex()&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO nodes (node_id, profile) VALUES (?, ?)&quot;,&#10;            (node_id, json.dumps(profile))&#10;        )&#10;        self.conn.commit()&#10;        return node_id&#10;&#10;    def add_job(self, job):&#10;        &quot;&quot;&quot;Insert a new job with pending status.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO jobs (job_id, job, assigned_node, status) &quot;&#10;            &quot;VALUES (?, ?, ?, ?)&quot;,&#10;            (job[&quot;job_id&quot;], json.dumps(job), None, &quot;pending&quot;)&#10;        )&#10;        self.conn.commit()&#10;&#10;    def assign_job(self, node_id):&#10;        &quot;&quot;&quot;Assign the first pending job to the given node.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT job_id, job FROM jobs WHERE status = ? LIMIT 1&quot;,&#10;            (&quot;pending&quot;,)&#10;        )&#10;        row = c.fetchone()&#10;        if row:&#10;            job_id, job_json = row&#10;            c.execute(&#10;                &quot;UPDATE jobs SET assigned_node = ?, status = ? WHERE job_id = ?&quot;,&#10;                (node_id, &quot;assigned&quot;, job_id)&#10;            )&#10;            self.conn.commit()&#10;            return json.loads(job_json)&#10;        return None&#10;&#10;    def store_result(self, result):&#10;        &quot;&quot;&quot;Store job result and mark the job as completed.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO results (job_id, node_id, result) VALUES (?, ?, ?)&quot;,&#10;            (result[&quot;job_id&quot;], result.get(&quot;node_id&quot;, &quot;&quot;), json.dumps(result))&#10;        )&#10;        c.execute(&#10;            &quot;UPDATE jobs SET status = ? WHERE job_id = ?&quot;,&#10;            (&quot;completed&quot;, result[&quot;job_id&quot;])&#10;        )&#10;        self.conn.commit()&#10;&#10;    def add_vote(self, result):&#10;        &quot;&quot;&quot;Record a vote for a job result from a node.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;INSERT INTO votes (job_id, sha256, node_id, result) &quot;&#10;            &quot;VALUES (?, ?, ?, ?)&quot;,&#10;            (result[&quot;job_id&quot;], result[&quot;sha256&quot;], result.get(&quot;node_id&quot;, &quot;&quot;), &#10;             json.dumps(result))&#10;        )&#10;        self.conn.commit()&#10;&#10;    def count_votes(self, job_id, sha256):&#10;        &quot;&quot;&quot;Count distinct votes for a given job_id and hash.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT COUNT(DISTINCT node_id) FROM votes &quot;&#10;            &quot;WHERE job_id = ? AND sha256 = ?&quot;,&#10;            (job_id, sha256)&#10;        )&#10;        row = c.fetchone()&#10;        return row[0] if row else 0&#10;&#10;    def get_vote_result(self, job_id, sha256):&#10;        &quot;&quot;&quot;Retrieve the recorded result for a job and hash.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT result FROM votes &quot;&#10;            &quot;WHERE job_id = ? AND sha256 = ? LIMIT 1&quot;,&#10;            (job_id, sha256)&#10;        )&#10;        row = c.fetchone()&#10;        return json.loads(row[0]) if row else None&#10;&#10;    def finalize_job(self, result):&#10;        &quot;&quot;&quot;Finalize a job by storing its final result.&quot;&quot;&quot;&#10;        self.store_result(result)&#10;&#10;    def get_node_profile(self, node_id):&#10;        &quot;&quot;&quot;Retrieve stored node profile for a given node_id.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT profile FROM nodes WHERE node_id = ?&quot;,&#10;            (node_id,)&#10;        )&#10;        row = c.fetchone()&#10;        return json.loads(row[0]) if row else None&#10;&#10;    def get_pending_jobs(self):&#10;        &quot;&quot;&quot;Return a list of (job_id, job dict) for all pending jobs.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;SELECT job_id, job FROM jobs WHERE status = ?&quot;,&#10;            (&quot;pending&quot;,)&#10;        )&#10;        rows = c.fetchall()&#10;        return [(job_id, json.loads(job_json)) for job_id, job_json in rows]&#10;&#10;    def assign_job_to_node(self, job_id, node_id):&#10;        &quot;&quot;&quot;Mark a job as assigned to a specific node.&quot;&quot;&quot;&#10;        c = self.conn.cursor()&#10;        c.execute(&#10;            &quot;UPDATE jobs SET assigned_node = ?, status = ? WHERE job_id = ?&quot;,&#10;            (node_id, &quot;assigned&quot;, job_id)&#10;        )&#10;        self.conn.commit()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>